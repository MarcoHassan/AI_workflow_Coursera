{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# CASE STUDY - topic modeling and feature engineering\n",
    "\n",
    "\n",
    "[Feature\n",
    "engineering](https://en.wikipedia.org/wiki/Feature_engineering) is the\n",
    "process of using domain knowledge of your data to create features that\n",
    "can be leveraged by machine learning.  That is not a hard definition,\n",
    "because sometimes it is used in a context where features are\n",
    "transformed for machine learning, but the inclusion of domain\n",
    "knowledge is not implied.\n",
    "\n",
    "It is unfortunately common that for large datasets engineered features\n",
    "are not easy to create.  When there are many features generally only a\n",
    "small number play an important roll when it comes to prediction.\n",
    "Furthermore, domain insight is even more difficult to fold into the\n",
    "model when there are hundreds or thousands of features to keep in\n",
    "mind.  However, there is a middle ground---much of the worlds\n",
    "knowledge is locked up in language.  In this case study we will use\n",
    "topic modeling to gather insight from text.  Ideally, the result of\n",
    "these types of experiments would be shared with domain experts to\n",
    "further engineer features that are relevant when it comes to your\n",
    "business opportunity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcohassan/Desktop/python_venv/TreeSchutz/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from string import punctuation, printable\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "\n",
    "try:\n",
    "    import pyLDAvis\n",
    "    import pyLDAvis.sklearn\n",
    "except:\n",
    "    raise Exception(\"'pip install pyldavis' before running this notebook\")\n",
    "\n",
    "pyLDAvis.enable_notebook()    \n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline\n",
    "\n",
    "## supress all warnings (not to be used during development)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Synopsis\n",
    "\n",
    "   >Goal: AAVAIL has recently enabled comments on the core streaming\n",
    "    service.  The data science team knows that this will be an\n",
    "    incredibly important source of data going forward.  It will be\n",
    "    used inform customer retention, product quality, product market\n",
    "    fit and more.  Comments are going live next week and being the\n",
    "    diligent data scientist that you are your plan is to build a topic\n",
    "    modeling pipeline that that will consume the comments and create\n",
    "    visualizations that can be used to communicate with domain\n",
    "    experts.\n",
    "  \n",
    "## Outline\n",
    "\n",
    "1. EDA - summary tables, use tSNE to visualize the data\n",
    "2. Create a transfomation pipelines for NMF and LDA\n",
    "3. Use ldaviz and wordclouds to get insight into the clusters\n",
    "\n",
    "## Data\n",
    "\n",
    "Here we see how to load the data.\n",
    "\n",
    "* [download the movie review data](http://www.nltk.org/nltk_data)\n",
    "\n",
    "* For more examples of applications with these data see [NLTK's book chapter that uses these data](https://www.nltk.org/book/ch06.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"arnold schwarzenegger has been an icon for action enthusiasts , since the late 80's , but lately his films have been very sloppy and the one-liners are getting worse . \\nit's hard seeing arnold as mr . freeze in batman and robin , especially when he says tons of ice jokes , but hey he got 15 million , what's it matter to him ? \\nonce again arnold has signed to do another expensive blockbuster , that can't compare with the likes of the terminator series , true lies and even eraser . \\nin this so called dark thriller , the devil ( gabriel byrne ) has come upon earth , to impregnate a woman ( robin tunney ) which happens every 1000 years , and basically destroy the world , but apparently god has chosen one man , and that one man is jericho cane ( arnold himself ) . \\nwith the help of a trusty sidekick ( kevin pollack ) , they will stop at nothing to let the devil take over the world ! \\nparts of this are actually so absurd , that they would fit right in with dogma . \\nyes , the film is that weak , but it's better than the other blockbuster right now ( sleepy hollow ) , but it makes the world is not enough look like a 4 star film . \\nanyway , this definitely doesn't seem like an arnold movie . \\nit just wasn't the type of film you can see him doing . \\nsure he gave us a few chuckles with his well known one-liners , but he seemed confused as to where his character and the film was going . \\nit's understandable , especially when the ending had to be changed according to some sources . \\naside form that , he still walked through it , much like he has in the past few films . \\ni'm sorry to say this arnold but maybe these are the end of your action days . \\nspeaking of action , where was it in this film ? \\nthere was hardly any explosions or fights . \\nthe devil made a few places explode , but arnold wasn't kicking some devil butt . \\nthe ending was changed to make it more spiritual , which undoubtedly ruined the film . \\ni was at least hoping for a cool ending if nothing else occurred , but once again i was let down . \\ni also don't know why the film took so long and cost so much . \\nthere was really no super affects at all , unless you consider an invisible devil , who was in it for 5 minutes tops , worth the overpriced budget . \\nthe budget should have gone into a better script , where at least audiences could be somewhat entertained instead of facing boredom . \\nit's pitiful to see how scripts like these get bought and made into a movie . \\ndo they even read these things anymore ? \\nit sure doesn't seem like it . \\nthankfully gabriel's performance gave some light to this poor film . \\nwhen he walks down the street searching for robin tunney , you can't help but feel that he looked like a devil . \\nthe guy is creepy looking anyway ! \\nwhen it's all over , you're just glad it's the end of the movie . \\ndon't bother to see this , if you're expecting a solid action flick , because it's neither solid nor does it have action . \\nit's just another movie that we are suckered in to seeing , due to a strategic marketing campaign . \\nsave your money and see the world is not enough for an entertaining experience . \\n\"\n"
     ]
    }
   ],
   "source": [
    "movie_reviews = load_files(os.path.join(\".\",\"movie_reviews\"), shuffle=True)\n",
    "X = movie_reviews.data\n",
    "y = movie_reviews.target\n",
    "target_names = movie_reviews.target_names\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### QUESTION 1\n",
    "\n",
    "The main focus of this exercise is to enable visualization of topics,\n",
    "but these topics can be used as additional features for prediction\n",
    "tasks.  \n",
    "\n",
    "The goal of this case study is to ensure that you are comfortable with\n",
    "natural language processing pipelines and topic modeling tools.\n",
    "\n",
    "There are many ways to process tokens (words, dates, emojis etc).\n",
    "NLTK is often used to pre-process text data before the tokens are\n",
    "vectorized.  Generally, the tokens are modified via [stemming or\n",
    "lemmatization](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html).\n",
    "The next code block provides a lemmatization function that makes use\n",
    "of the library [spacy](https://spacy.io/).  You will need to install\n",
    "it and download the English language reference material as follows.\n",
    "Stopwords are words that are very common or otherwise irrelevant we\n",
    "use a default list here, but it is an important part of NLP pipelines\n",
    "that needs to be customized for the subject area. Use the following\n",
    "function to process the corpus (this can take a few minutes)\n",
    "\n",
    "```bash\n",
    "~$ pip install spacy\n",
    "~$ python -m spacy download en\n",
    "```\n",
    "\n",
    "If you prefer to use NLTK then you could use a simple lemmatizer like the WordLemmatizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading English Module...\n",
      "pron fool people time people time pron fool people time abraham lincoln\n",
      "\n",
      "pron can fool some of the people all of the time and all of the people some of the time but pron can not fool all of the people all of the time abraham lincoln\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "STOPLIST = ENGLISH_STOP_WORDS\n",
    "STOPLIST = set(list(STOPLIST) + [\"foo\"])\n",
    "\n",
    "if not 'nlp' in locals():\n",
    "    print(\"Loading English Module...\")\n",
    "    nlp = spacy.load('en')\n",
    "\n",
    "def lemmatize_document(doc, stop_words=None):\n",
    "    \"\"\"\n",
    "    takes a list of strings where each string is a document\n",
    "    returns a processed list of strings\n",
    "    \"\"\"\n",
    "    \n",
    "    if not stop_words:\n",
    "        stop_words = set([])\n",
    "  \n",
    "    ## ensure working with string\n",
    "    doc = str(doc)\n",
    "\n",
    "    # First remove punctuation form string\n",
    "    if sys.version_info.major == 3:\n",
    "        PUNCT_DICT = {ord(punc): None for punc in punctuation}\n",
    "        doc = doc.translate(PUNCT_DICT)\n",
    "\n",
    "    # remove unicode\n",
    "    clean_doc = \"\".join([char for char in doc if char in printable])\n",
    "            \n",
    "    # Run the doc through spaCy\n",
    "    doc = nlp(clean_doc)\n",
    "\n",
    "    # Lemmatize and lower text\n",
    "    tokens = [re.sub(\"\\W+\",\"\",token.lemma_.lower()) for token in doc ]\n",
    "    tokens = [t for t in tokens if len(t) > 1]\n",
    "    \n",
    "    return ' '.join(w for w in tokens if w not in stop_words)    \n",
    "\n",
    "## example usage\n",
    "corpus = ['\"You can fool some of the people all of the time, and all of the people some of the time, but you can not fool all of the people all of the time\". -- Abraham Lincoln']\n",
    "processed = [lemmatize_document(doc, STOPLIST) for doc in corpus]\n",
    "print(processed[0])\n",
    "processed = [lemmatize_document(doc, None) for doc in corpus]\n",
    "print(\"\\n\"+processed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "## Use stemming or lemmatization to process the corpus\n",
    "processed = [lemmatize_document(doc, STOPLIST) for doc in X]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Prepreocessing:\n",
      "-----------------------------------\n",
      "b\"arnold schwarzenegger has been an icon for action enthusiasts , since the late 80's , but lately his films have been very sloppy and the one-liners are getting worse . \\nit's hard seeing arnold as mr . freeze in batman and robin , especially when he says tons of ice jokes , but hey he got 15 million , what's it matter to him ? \\nonce again arnold has signed to do another expensive blockbuster , that can't compare with the likes of the terminator series , true lies and even eraser . \\nin this so called dark thriller , the devil ( gabriel byrne ) has come upon earth , to impregnate a woman ( robin tunney ) which happens every 1000 years , and basically destroy the world , but apparently god has chosen one man , and that one man is jericho cane ( arnold himself ) . \\nwith the help of a trusty sidekick ( kevin pollack ) , they will stop at nothing to let the devil take over the world ! \\nparts of this are actually so absurd , that they would fit right in with dogma . \\nyes , the film is that weak , but it's better than the other blockbuster right now ( sleepy hollow ) , but it makes the world is not enough look like a 4 star film . \\nanyway , this definitely doesn't seem like an arnold movie . \\nit just wasn't the type of film you can see him doing . \\nsure he gave us a few chuckles with his well known one-liners , but he seemed confused as to where his character and the film was going . \\nit's understandable , especially when the ending had to be changed according to some sources . \\naside form that , he still walked through it , much like he has in the past few films . \\ni'm sorry to say this arnold but maybe these are the end of your action days . \\nspeaking of action , where was it in this film ? \\nthere was hardly any explosions or fights . \\nthe devil made a few places explode , but arnold wasn't kicking some devil butt . \\nthe ending was changed to make it more spiritual , which undoubtedly ruined the film . \\ni was at least hoping for a cool ending if nothing else occurred , but once again i was let down . \\ni also don't know why the film took so long and cost so much . \\nthere was really no super affects at all , unless you consider an invisible devil , who was in it for 5 minutes tops , worth the overpriced budget . \\nthe budget should have gone into a better script , where at least audiences could be somewhat entertained instead of facing boredom . \\nit's pitiful to see how scripts like these get bought and made into a movie . \\ndo they even read these things anymore ? \\nit sure doesn't seem like it . \\nthankfully gabriel's performance gave some light to this poor film . \\nwhen he walks down the street searching for robin tunney , you can't help but feel that he looked like a devil . \\nthe guy is creepy looking anyway ! \\nwhen it's all over , you're just glad it's the end of the movie . \\ndon't bother to see this , if you're expecting a solid action flick , because it's neither solid nor does it have action . \\nit's just another movie that we are suckered in to seeing , due to a strategic marketing campaign . \\nsave your money and see the world is not enough for an entertaining experience . \\n\"\n",
      "\n",
      "After Preprocessing\n",
      "-----------------------------------\n",
      "barnold schwarzenegger icon action enthusiast late 80 lately pron film sloppy oneliner bad nit hard seeing arnold mr freeze batman robin especially pron say ton ice joke hey pron 15 million pron matter pron nonce arnold sign expensive blockbuster compare like terminator series true lie eraser nin dark thriller devil gabriel byrne come earth impregnate woman robin tunney happen 1000 year basically destroy world apparently god choose man man jericho cane arnold pron nwith help trusty sidekick kevin pollack pron stop let devil world npart actually absurd pron fit right dogma nye film weak pron blockbuster right sleepy hollow pron make world look like star film nanyway definitely like arnold movie nit just type film pron pron nsure pron pron chuckle pron know oneliner pron confused pron character film nit understandable especially ending change accord source naside form pron walk pron like pron past film nim sorry say arnold maybe end pron action day nspeake action pron film nthere hardly explosion fight nthe devil make place explode arnold kick devil butt nthe ending change make pron spiritual undoubtedly ruin film ni hope cool ending occur let ni know film long cost nthere really super affect unless pron consider invisible devil pron minute worth overpriced budget nthe budget script audience somewhat entertain instead face boredom nit pitiful script like buy make movie ndo pron read thing anymore nit sure like pron nthankfully gabriel performance light poor film nwhen pron walk street search robin tunney pron help feel pron look like devil nthe guy creepy look nwhen pron pron just glad pron end movie ndont bother pron expect solid action flick pron solid pron action nit just movie pron suckere strategic marketing campaign nsave pron money world entertaining experience\n"
     ]
    }
   ],
   "source": [
    "print(\"Before Prepreocessing:\\n{}\\n{}\\n\\nAfter Preprocessing\\n{}\\n{}\".format(\"-\"*35 , X[0], \"-\"*35, processed[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### QUESTION 2\n",
    "\n",
    "Use the CountVectorizer from sklearn to vectorize the tokens.\n",
    "\n",
    "Additional resources:\n",
    "\n",
    "* [scikit-learn CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n",
    "* [scikit-learn working with text](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)\n",
    "\n",
    "Because this is an exercise in visualization set the `max_features` to\n",
    "something like 1000.  In the context of supervised learning it is\n",
    "reasonable to grid-search to optimize this parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 1 0]]\n",
      "(2000, 1000)\n"
     ]
    }
   ],
   "source": [
    "max_features = 1000\n",
    "vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=max_features,\n",
    "                                stop_words='english')\n",
    "X = vectorizer.fit_transform(processed)\n",
    "\n",
    "print(X.toarray())\n",
    "\n",
    "## x dimension = number of rows.\n",
    "## y dimension = number of columns.\n",
    "print(X.toarray().shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### QUESTION 3\n",
    "\n",
    "Use model the corpus with LDA.  For example, you could use something like the following.\n",
    "\n",
    "```python\n",
    "n_topics = 10\n",
    "lda_model = LatentDirichletAllocation(n_components=n_topics, max_iter=5,\n",
    "                                      learning_method='online',\n",
    "                                      learning_offset=50.,\n",
    "                                      random_state=0)\n",
    "\n",
    "lda_model.fit(tf)\n",
    "```\n",
    "\n",
    "You could use a pipeline here to make it easier to iterate on changes.\n",
    "\n",
    "* [scikit-learn's LDA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html)\n",
    "* [scikit-learn's user guide for LDA](https://scikit-learn.org/stable/modules/decomposition.html#latentdirichletallocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "n_topics = 4\n",
    "lda_model = LatentDirichletAllocation(n_components=n_topics, max_iter=5,\n",
    "                                      learning_method='online',\n",
    "                                      learning_offset=50.,\n",
    "                                      random_state=0)\n",
    "\n",
    "lda_fit = lda_model.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "## put everything into a pipeline\n",
    "n_topics = 4\n",
    "\n",
    "pipe = Pipeline([(\"vectorize\", CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=max_features,\n",
    "                                stop_words='english')), \n",
    "                 (\"lda\", LatentDirichletAllocation(n_components=n_topics, \n",
    "                                                   max_iter=5,\n",
    "                                                   learning_method='online',\n",
    "                                                   learning_offset=50.,\n",
    "                                                   random_state=0))]) \n",
    "\n",
    "## train the data\n",
    "pipe_fit = pipe.fit(processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## QUESTION 4\n",
    "\n",
    "Visualize the corpus using [pyldavis](https://github.com/bmabey/pyLDAvis).\n",
    "\n",
    "This is a very strong visualization tool when performing latent\n",
    "drichlet allocation. It is a package that was constructed for\n",
    "performing the task very well.\n",
    "\n",
    "```python\n",
    "pyLDAvis.sklearn.prepare(lda_model,tf, tf_vectorizer, R=20)\n",
    "```\n",
    "\n",
    "* [PyLDAViz documentation](https://pyldavis.readthedocs.io/en/latest)\n",
    "* [PyLDAViz demos](https://pyldavis.readthedocs.io/en/latest/readme.html#video-demos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el9091553505607203031992176\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el9091553505607203031992176_data = {\"mdsDat\": {\"x\": [-0.0008111353153983683, -0.016511930471538226, -0.06300242102893101, 0.08032548681586756], \"y\": [-0.018992631954789414, -0.05417953220662124, 0.047357169116518986, 0.025814995044891636], \"topics\": [1, 2, 3, 4], \"cluster\": [1, 1, 1, 1], \"Freq\": [47.823503551129896, 34.9650514695721, 11.493648604039569, 5.717796375258442]}, \"tinfo\": {\"Term\": [\"film\", \"movie\", \"nthe\", \"alien\", \"effect\", \"make\", \"horror\", \"star\", \"scream\", \"killer\", \"time\", \"character\", \"know\", \"scene\", \"special\", \"like\", \"original\", \"jackie\", \"vampire\", \"action\", \"plot\", \"just\", \"murder\", \"series\", \"ship\", \"good\", \"new\", \"human\", \"year\", \"bad\", \"stupid\", \"batman\", \"dumb\", \"bob\", \"joke\", \"sean\", \"funny\", \"noh\", \"laugh\", \"car\", \"guy\", \"gag\", \"nmaybe\", \"bunch\", \"nwell\", \"robin\", \"bad\", \"mike\", \"guess\", \"nim\", \"awful\", \"comedy\", \"boring\", \"hunt\", \"pretty\", \"bond\", \"waste\", \"sit\", \"cute\", \"jack\", \"movie\", \"ni\", \"think\", \"just\", \"really\", \"nyou\", \"thing\", \"nand\", \"like\", \"good\", \"play\", \"know\", \"kid\", \"big\", \"try\", \"say\", \"watch\", \"girl\", \"nit\", \"make\", \"film\", \"nthe\", \"scene\", \"character\", \"plot\", \"time\", \"way\", \"nbut\", \"come\", \"look\", \"nhe\", \"end\", \"people\", \"work\", \"tarzan\", \"disney\", \"political\", \"animate\", \"musical\", \"animation\", \"army\", \"beauty\", \"adult\", \"image\", \"country\", \"color\", \"soldier\", \"effective\", \"marry\", \"family\", \"desire\", \"issue\", \"mother\", \"novel\", \"sister\", \"affair\", \"cinematography\", \"child\", \"tale\", \"artist\", \"singer\", \"husband\", \"complex\", \"wedding\", \"emotional\", \"father\", \"dream\", \"life\", \"voice\", \"american\", \"story\", \"young\", \"relationship\", \"film\", \"man\", \"nthe\", \"love\", \"performance\", \"character\", \"world\", \"make\", \"nhe\", \"daughter\", \"tell\", \"great\", \"nit\", \"time\", \"nin\", \"year\", \"live\", \"work\", \"new\", \"scene\", \"way\", \"like\", \"good\", \"come\", \"nbut\", \"use\", \"role\", \"play\", \"end\", \"movie\", \"nthis\", \"mars\", \"trek\", \"alien\", \"planet\", \"ship\", \"scifi\", \"ape\", \"science\", \"menace\", \"space\", \"computer\", \"earth\", \"toy\", \"scientist\", \"crew\", \"titanic\", \"creature\", \"mission\", \"race\", \"dr\", \"effect\", \"murphy\", \"special\", \"cameron\", \"machine\", \"episode\", \"impact\", \"simon\", \"fiction\", \"monster\", \"human\", \"series\", \"star\", \"war\", \"original\", \"film\", \"nthe\", \"movie\", \"action\", \"make\", \"like\", \"good\", \"time\", \"nit\", \"just\", \"year\", \"character\", \"look\", \"nin\", \"story\", \"scene\", \"plot\", \"know\", \"vampire\", \"chan\", \"jackie\", \"truman\", \"godzilla\", \"carter\", \"scream\", \"harry\", \"killer\", \"legend\", \"horror\", \"lee\", \"scare\", \"master\", \"sequel\", \"rush\", \"scary\", \"summer\", \"sam\", \"murder\", \"blood\", \"wood\", \"genre\", \"joe\", \"brown\", \"victim\", \"art\", \"guard\", \"college\", \"detective\", \"flick\", \"suspense\", \"death\", \"movie\", \"film\", \"nthe\", \"release\", \"make\", \"scene\", \"character\", \"know\", \"time\", \"original\", \"like\", \"good\", \"plot\", \"new\", \"nit\", \"just\", \"nthis\"], \"Freq\": [11017.0, 6691.0, 7808.0, 602.0, 818.0, 4097.0, 459.0, 1168.0, 345.0, 344.0, 2800.0, 3832.0, 1858.0, 2600.0, 571.0, 3625.0, 723.0, 243.0, 239.0, 1154.0, 1458.0, 2723.0, 377.0, 552.0, 311.0, 3350.0, 1304.0, 549.0, 1556.0, 1845.0, 235.13521905779675, 172.11156589362133, 159.0319831612316, 133.1677970017057, 328.84631753654156, 93.63620549715574, 706.8454923174936, 91.26595458504028, 507.0969929285421, 306.8265959321012, 727.8699536893624, 134.5828012100161, 105.41062835531277, 142.67682711802783, 205.1765233687018, 142.37554251930786, 1493.431887443404, 88.58866891285632, 216.80833098664087, 159.7016964499479, 98.92645665968183, 692.6807987842126, 159.89495029222806, 115.26512838004939, 398.26766593981625, 121.1703994407472, 220.21003964208003, 227.60193074795762, 95.15715655112629, 186.99376326379797, 4766.854927759637, 1351.5760841568258, 1019.6547629423148, 1846.0636733053095, 1050.0112828832175, 282.41522622568476, 1044.2682666774535, 1059.8077912463395, 2157.3373802852825, 1980.3468625515864, 1387.1638579085595, 1146.9671120493747, 360.6923961438615, 736.7508929666802, 835.4342301829371, 928.898491312027, 708.4374592391117, 443.36877282376923, 1621.3865708795845, 2055.226130251467, 4575.710289910142, 3362.8545714645884, 1381.349047130181, 1868.784217411569, 861.5349744913717, 1395.905539243198, 1011.1963686928514, 995.5904327147089, 1025.4099020329002, 943.1125600386538, 861.4512268213226, 837.1316847130579, 804.5976898178315, 810.7202551477649, 111.93849494883278, 258.8778133552229, 133.43979870954118, 132.77645656230303, 144.41883084115207, 123.75052089822039, 129.10567907719005, 117.84690455116824, 160.5879993868487, 191.47733121868814, 145.5155367881615, 105.14392179680803, 115.05799726748936, 151.5560782736918, 117.22707729473052, 518.732427221065, 90.08413738233867, 122.49916253634288, 309.87326477295295, 202.71612581563434, 133.4463303649438, 84.77402842561803, 104.926388880597, 391.811370263329, 185.9303312675019, 89.99845294968814, 76.69133484817291, 186.76394538453434, 100.48975694318443, 124.17301607052346, 171.20529915490656, 321.7280407305132, 216.53017931356834, 1061.158663036182, 238.5971916449959, 333.75706477324906, 1319.7455895333972, 518.8050923547388, 299.6226715745077, 4412.153351639288, 942.1188062543281, 3083.052572319461, 683.6699522467312, 655.1063787920098, 1472.476498505262, 524.3969341495707, 1423.1627112889685, 693.7167485216903, 218.33969854713175, 455.7009388034032, 582.9511591953071, 1038.0319591986108, 934.7367651160201, 644.4657996833421, 619.8636245204094, 365.63201888310414, 636.3790861814142, 544.8127775611724, 839.2880984428893, 653.9039613205166, 961.4619707344344, 909.8414041462746, 616.1362751087906, 580.336639626926, 462.35766535893856, 468.4133473812741, 616.6933379564683, 524.3077937731042, 831.0165556309852, 521.2058509195986, 144.5003248493518, 170.5539224283372, 594.1321036728023, 268.36239241440563, 296.65587033339057, 117.36885248459043, 125.46335885322526, 192.131960545624, 110.47142053083716, 236.4906197438608, 199.56345396904914, 252.71606531350227, 134.68716858384946, 106.51139804044082, 175.81230629981624, 84.19952398874752, 116.37063078112665, 154.00019883558016, 112.04335134950121, 140.2367796147584, 533.8228700128119, 85.88858214039068, 355.26139438394324, 80.15505717038705, 77.91079066958346, 85.82379574464822, 77.13590534837103, 64.01350224888519, 125.35382016974245, 90.55610082234823, 268.7324506756015, 258.98063973024983, 432.14763361006675, 218.14047756748667, 240.86109204361313, 1420.248556833961, 1009.9867594159311, 640.4036482034877, 246.7175688505705, 392.7339109137552, 366.3782597862139, 340.36982083872647, 315.1298291541076, 296.68762761300883, 285.175458430962, 242.7410032772413, 308.2573487095116, 232.99036792845308, 212.98899127672246, 218.40438301714778, 220.05512800776833, 208.66765860306165, 207.80840988371776, 237.4985591605733, 149.88985743252948, 233.58623970939485, 128.7571466444467, 113.10996740794691, 142.8464083045482, 264.6834181434488, 111.74469019942339, 244.36996528062255, 84.17352483402775, 288.1278047244947, 124.52808835837406, 58.4111819619483, 77.69640076429727, 117.95940326096849, 52.27872989125292, 71.47916678024416, 131.1493939743253, 57.29042688634722, 130.77118959380192, 67.47828416831403, 40.00044559329852, 85.54019981943664, 83.44875621755453, 36.887216873289695, 48.02096912715611, 77.95923620849891, 30.813003022434373, 34.76387053628398, 35.41207653071239, 63.6506167071806, 45.30184186643819, 86.34499307741615, 453.1516492185805, 609.2036557500278, 352.54403726652, 77.91853583139738, 226.25211085807118, 160.256455111741, 182.58205679481887, 136.5087357599279, 155.11473175478798, 94.48154614268516, 140.5540151093323, 119.64333854588405, 103.11052206039885, 100.92918476110498, 109.95553970660387, 105.95169505204362, 94.98400574174964], \"Total\": [11017.0, 6691.0, 7808.0, 602.0, 818.0, 4097.0, 459.0, 1168.0, 345.0, 344.0, 2800.0, 3832.0, 1858.0, 2600.0, 571.0, 3625.0, 723.0, 243.0, 239.0, 1154.0, 1458.0, 2723.0, 377.0, 552.0, 311.0, 3350.0, 1304.0, 549.0, 1556.0, 1845.0, 246.30368115650185, 183.9438774670232, 176.60656672346133, 150.23632785604482, 381.5729278300277, 110.07082005286033, 831.9143564774562, 107.76611747804097, 599.0008969733467, 363.0729784626853, 870.1293982881859, 161.6486764915087, 128.9747922936913, 175.2726357311257, 252.1539205869716, 175.07643195191793, 1845.1464223615694, 109.51888874960058, 268.377821456142, 198.28589135650998, 123.3912964684515, 866.4476097023489, 200.75477711411276, 145.25560735490677, 502.7600306556723, 153.1404607125046, 279.7234373174635, 289.67524286571717, 122.97674101944057, 242.04387682538808, 6691.42678081269, 1854.8757238781943, 1389.912500598577, 2723.85814340502, 1511.3225330733005, 376.4701549663808, 1562.6343567922481, 1602.56170450725, 3625.7316259152635, 3350.2014260824712, 2252.4714998012846, 1858.9607685049994, 499.5551924267334, 1133.9935032997269, 1311.2813499068209, 1521.231967524107, 1112.5864721801265, 638.9183529292842, 3066.061697397808, 4097.374863312261, 11017.31585413342, 7808.437940466501, 2600.94872869258, 3832.1001214211615, 1458.8987947861783, 2800.8868652681135, 1811.9960911096023, 1790.0730691362876, 1921.0156181306588, 1744.4997120216233, 1624.485859327183, 1528.6957000421075, 1417.4572984268284, 1659.4634961662996, 112.99358153010957, 278.3100957460191, 147.87288970734383, 148.42150145716954, 169.65928922685708, 145.46315228999146, 154.47694366876408, 141.67910826032013, 197.8817559036575, 237.16591727177712, 185.24955389113853, 135.06635710117197, 149.84072764686695, 197.43700079112304, 152.86512275570817, 680.4883216843826, 119.62621115331149, 164.67947525201677, 417.9098332367543, 274.80309722125344, 180.94953352606544, 115.03077187215405, 142.8646499541454, 534.3269247949454, 257.22451799637116, 124.91376809632784, 106.74612571176574, 260.3485265995834, 140.3961726657793, 173.48496184983549, 239.57085021803127, 460.38879871041706, 307.43763773283666, 1634.6200013670104, 343.14237858498467, 503.65961827309536, 2321.1288687472984, 840.0420311412203, 451.2919105611134, 11017.31585413342, 1820.519993652723, 7808.437940466501, 1310.4627577123006, 1304.9338525683881, 3832.1001214211615, 1027.3059692842587, 4097.374863312261, 1624.485859327183, 322.61355788888085, 911.8754379100366, 1310.146079491452, 3066.061697397808, 2800.8868652681135, 1598.11404839665, 1556.9438565019364, 697.5739199918926, 1659.4634961662996, 1304.6524729741127, 2600.94872869258, 1811.9960911096023, 3625.7316259152635, 3350.2014260824712, 1921.0156181306588, 1790.0730691362876, 1104.7104461532774, 1140.3810953949069, 2252.4714998012846, 1528.6957000421075, 6691.42678081269, 1572.0010364732352, 145.72184555306615, 172.51734673326092, 602.9209219628883, 274.5767628115749, 311.0421878075016, 125.80712243032335, 136.0769461337629, 218.10478817097265, 131.21282734565648, 285.8702185041778, 241.5556576625667, 306.64230376165307, 166.9489959519782, 134.85338139544385, 222.9095384576154, 113.31136209467053, 159.4838651301415, 223.74346459854823, 163.7812779945794, 212.26285812440904, 818.5412297441616, 137.068834539576, 571.9387013435207, 129.06424596569173, 134.32315535761683, 153.100826293565, 142.52802717735827, 118.36332082492878, 237.04580775565793, 171.38735479097448, 549.3116355914963, 552.7166447396212, 1168.856183308201, 530.2977404633423, 723.8728101445568, 11017.31585413342, 7808.437940466501, 6691.42678081269, 1154.3779045009067, 4097.374863312261, 3625.7316259152635, 3350.2014260824712, 2800.8868652681135, 3066.061697397808, 2723.85814340502, 1556.9438565019364, 3832.1001214211615, 1744.4997120216233, 1598.11404839665, 2321.1288687472984, 2600.94872869258, 1458.8987947861783, 1858.9607685049994, 239.73883382188086, 151.8088180477719, 243.49946148324437, 140.22142474632528, 133.95066338699982, 170.17630525113952, 345.19047406631324, 154.3639877487533, 344.67229682365127, 129.27616154665634, 459.94586377042395, 258.08169823796237, 121.19368578563126, 172.88732397298696, 272.5387669798488, 126.37213511530086, 189.90629290126984, 354.17638276307264, 154.99110910502958, 377.7528569203075, 196.8121805749604, 121.30147495704388, 276.14616508373047, 277.2370769373698, 124.60949703288316, 176.73269386072928, 294.46415812534076, 117.24678637887354, 132.96330214271953, 141.47813430386606, 265.6639863671779, 190.5191975727588, 471.28320231203566, 6691.42678081269, 11017.31585413342, 7808.437940466501, 449.7689662628882, 4097.374863312261, 2600.94872869258, 3832.1001214211615, 1858.9607685049994, 2800.8868652681135, 723.8728101445568, 3625.7316259152635, 3350.2014260824712, 1458.8987947861783, 1304.6524729741127, 3066.061697397808, 2723.85814340502, 1572.0010364732352], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.6074, -6.9194, -6.9984, -7.1759, -6.2719, -7.5281, -5.5067, -7.5537, -5.8388, -6.3412, -5.4774, -7.1653, -7.4097, -7.1069, -6.7436, -7.109, -4.7587, -7.5835, -6.6885, -6.9942, -7.4731, -5.5269, -6.993, -7.3203, -6.0804, -7.2703, -6.6729, -6.6399, -7.512, -6.8364, -3.5981, -4.8585, -5.1403, -4.5467, -5.111, -6.4241, -5.1164, -5.1017, -4.3909, -4.4765, -4.8325, -5.0226, -6.1795, -5.4653, -5.3396, -5.2335, -5.5045, -5.9731, -4.6765, -4.4394, -3.639, -3.947, -4.8367, -4.5345, -5.3088, -4.8262, -5.1486, -5.1642, -5.1347, -5.2183, -5.3089, -5.3375, -5.3772, -5.3696, -7.0364, -6.198, -6.8607, -6.8657, -6.7816, -6.9361, -6.8937, -6.985, -6.6755, -6.4996, -6.7741, -7.099, -7.0089, -6.7334, -6.9902, -5.503, -7.2536, -6.9462, -6.0182, -6.4425, -6.8606, -7.3144, -7.1011, -5.7836, -6.529, -7.2546, -7.4146, -6.5245, -7.1443, -6.9327, -6.6115, -5.9806, -6.3766, -4.7872, -6.2796, -5.9439, -4.5692, -5.5028, -6.0518, -3.3622, -4.9062, -3.7207, -5.2269, -5.2695, -4.4596, -5.4921, -4.4937, -5.2123, -6.3683, -5.6325, -5.3862, -4.8093, -4.9141, -5.2859, -5.3248, -5.8527, -5.2986, -5.4539, -5.0218, -5.2714, -4.8859, -4.9411, -5.3309, -5.3907, -5.618, -5.605, -5.33, -5.4923, -5.0317, -5.4982, -5.6685, -5.5027, -4.2547, -5.0495, -4.9492, -5.8765, -5.8098, -5.3836, -5.937, -5.1759, -5.3457, -5.1095, -5.7388, -5.9735, -5.4724, -6.2086, -5.885, -5.6048, -5.9229, -5.6985, -4.3617, -6.1887, -4.7689, -6.2578, -6.2862, -6.1895, -6.2962, -6.4827, -5.8107, -6.1358, -5.0481, -5.085, -4.573, -5.2567, -5.1576, -3.3832, -3.7241, -4.1797, -5.1335, -4.6687, -4.7381, -4.8118, -4.8888, -4.9491, -4.9887, -5.1498, -4.9109, -5.1908, -5.2806, -5.2554, -5.2479, -5.301, -5.3052, -4.4734, -4.9337, -4.49, -5.0857, -5.2152, -4.9818, -4.365, -5.2274, -4.4449, -5.5107, -4.2802, -5.119, -5.8761, -5.5908, -5.1732, -5.987, -5.6742, -5.0672, -5.8954, -5.0701, -5.7318, -6.2547, -5.4946, -5.5193, -6.3357, -6.0719, -5.5874, -6.5156, -6.395, -6.3765, -5.7902, -6.1302, -5.4852, -3.8274, -3.5314, -4.0784, -5.5879, -4.5219, -4.8668, -4.7364, -5.0272, -4.8994, -5.3952, -4.998, -5.1591, -5.3078, -5.3292, -5.2435, -5.2806, -5.3899], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.6912, 0.6712, 0.6328, 0.6171, 0.5889, 0.5759, 0.5747, 0.5715, 0.5711, 0.5693, 0.5591, 0.5544, 0.5359, 0.5319, 0.5315, 0.5309, 0.5262, 0.5256, 0.5243, 0.5213, 0.5167, 0.5138, 0.5101, 0.5064, 0.5047, 0.5035, 0.4984, 0.4965, 0.4812, 0.4796, 0.3985, 0.4211, 0.4279, 0.3487, 0.3735, 0.4502, 0.3346, 0.3241, 0.2185, 0.2119, 0.2529, 0.2548, 0.412, 0.3064, 0.2868, 0.2444, 0.2863, 0.3723, 0.1005, 0.0477, -0.1411, -0.1048, 0.1048, 0.0195, 0.2109, 0.0413, 0.1544, 0.151, 0.1099, 0.1226, 0.1033, 0.1355, 0.1714, 0.0213, 1.0414, 0.9784, 0.9481, 0.9394, 0.8897, 0.8892, 0.8714, 0.8666, 0.842, 0.8368, 0.8094, 0.8004, 0.7867, 0.7864, 0.7854, 0.7794, 0.7672, 0.7549, 0.7517, 0.7466, 0.7463, 0.7456, 0.7422, 0.7406, 0.7262, 0.723, 0.7202, 0.7186, 0.7164, 0.7164, 0.7148, 0.6925, 0.7003, 0.6188, 0.6875, 0.6393, 0.4862, 0.5689, 0.6412, 0.1357, 0.3921, 0.1215, 0.4002, 0.3617, 0.0944, 0.3784, -0.0066, 0.1999, 0.6604, 0.3572, 0.241, -0.0322, -0.0466, 0.1427, 0.1298, 0.4048, 0.0924, 0.1776, -0.0803, 0.0316, -0.2765, -0.2527, -0.0863, -0.0756, 0.1798, 0.1611, -0.2446, -0.0193, -1.0351, -0.0531, 2.155, 2.1519, 2.1487, 2.1405, 2.116, 2.0939, 2.0822, 2.0366, 1.9913, 1.9737, 1.9724, 1.97, 1.9486, 1.9274, 1.926, 1.8664, 1.8482, 1.7898, 1.7837, 1.7489, 1.7359, 1.6959, 1.6872, 1.687, 1.6187, 1.5846, 1.5494, 1.5487, 1.5263, 1.5254, 1.4484, 1.4053, 1.1684, 1.2751, 1.063, 0.1147, 0.1181, -0.1831, 0.6203, -0.1816, -0.1288, -0.1234, -0.0213, -0.1721, -0.0933, 0.3049, -0.3569, 0.1501, 0.148, -0.2001, -0.3064, 0.2187, -0.0278, 2.8522, 2.8489, 2.82, 2.7763, 2.6925, 2.6865, 2.596, 2.5385, 2.5177, 2.4325, 2.3939, 2.1328, 2.1317, 2.0618, 2.0241, 1.9789, 1.8845, 1.8681, 1.8664, 1.8008, 1.7911, 1.7522, 1.6896, 1.6609, 1.6443, 1.5586, 1.5326, 1.5252, 1.5201, 1.4765, 1.4328, 1.4252, 1.1645, 0.1692, -0.0335, -0.2362, 1.1085, -0.0349, 0.0747, -0.1824, 0.2502, -0.0319, 0.8254, -0.3886, -0.4707, 0.212, 0.3023, -0.4665, -0.3852, 0.0552]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4], \"Freq\": [0.5587425032003404, 0.15939321021529088, 0.21396805936509156, 0.06843512829895641, 0.16171273523355942, 0.8136171991438458, 0.02526761488024366, 0.20863982401747036, 0.7389327100618742, 0.034773304002911724, 0.017386652001455862, 0.008292961510975342, 0.0033171846043901364, 0.9852038275038705, 0.0033171846043901364, 0.18663398174008686, 0.663146275544564, 0.02184014679937187, 0.12905541290537922, 0.040425409668365594, 0.8960965809821041, 0.06063811450254839, 0.0481221525162949, 0.852449558860081, 0.10311889824920335, 0.07348783378905384, 0.918597922363173, 0.09062841138299178, 0.83507607631471, 0.07120803751520784, 0.006473457955927985, 0.19696794465325687, 0.4550638721299383, 0.08489997614364521, 0.26488792556817303, 0.18412702098829845, 0.7204970386498635, 0.024016567954995446, 0.07204970386498634, 0.8023256326293011, 0.08914729251436679, 0.06483439455590312, 0.04862579591692734, 0.8091498766201635, 0.07099707557752272, 0.0823782861662859, 0.03685344381123317, 0.9350678172522243, 0.021745763191912192, 0.03261864478786829, 0.010872881595956096, 0.14822227679055375, 0.8328680314897782, 0.01411640731338607, 0.6499155399527918, 0.19135912099017072, 0.12786669374919243, 0.031746213620489155, 0.2438873440646531, 0.3251831254195375, 0.08637676768956463, 0.3404260844235783, 0.8852719039261894, 0.0798741567452201, 0.006656179728768341, 0.026624718915073363, 0.79012430442636, 0.15018891737029982, 0.03264976464571735, 0.026119811716573883, 0.7969922424762675, 0.0697368212166734, 0.11456763485596345, 0.019924806061906688, 0.22470197430145383, 0.4654540896244401, 0.01605014102153242, 0.29692760889834974, 0.8158717954088792, 0.03993778019484025, 0.1084025462431378, 0.03423238302414878, 0.2789308513030761, 0.10072502963722194, 0.619846336229058, 0.845560033963122, 0.12118775731067545, 0.00275426721160626, 0.030296939327668863, 0.03525755240217159, 0.04701006986956212, 0.07639136353803844, 0.8403049989184229, 0.006587232631541307, 0.006587232631541307, 0.9880848947311961, 0.487722121233844, 0.38412357541798736, 0.0803736828999593, 0.04775449341133946, 0.23768220186309688, 0.7336332529947558, 0.026201187606955563, 0.0018715134004968258, 0.17499080428940353, 0.7349613780154949, 0.041997793029456845, 0.04899742520103299, 0.571586285653642, 0.16545918795237008, 0.007520872179653185, 0.2632305262878615, 0.17769043687187555, 0.7773956613144556, 0.02961507281197926, 0.01480753640598963, 0.5335719243123218, 0.32066371256233195, 0.10254992106295356, 0.04268575394498574, 0.7998175449269997, 0.1685041292342597, 0.012695516586142853, 0.018466205943480512, 0.17806753222193497, 0.7122701288877399, 0.09259511675540619, 0.014245402577754798, 0.11177548173066089, 0.05795765719367602, 0.8279665313382288, 0.14035121517905969, 0.7881260544670275, 0.06477748392879679, 0.01079624732146613, 0.08778317473416991, 0.1442152156347077, 0.727346304940265, 0.03762136060035853, 0.1166392437932561, 0.08075024570302346, 0.7895579579851182, 0.013458374283837242, 0.7725038020399491, 0.15450076040798982, 0.05692133278189098, 0.01626323793768314, 0.30376900661364814, 0.6757310555283194, 0.00929905122286678, 0.00929905122286678, 0.30130503124951624, 0.45832314612602476, 0.057290393265753095, 0.18248051188350986, 0.2340624160044285, 0.7523434800142346, 0.008359372000158162, 0.5371854836364153, 0.2049786713875795, 0.007068230047847569, 0.24738805167466493, 0.06467605837923494, 0.9306166177901029, 0.0035931143544019415, 0.1978678718034761, 0.13191191453565074, 0.6595595726782536, 0.004711139804844669, 0.26021537437625, 0.705834202995578, 0.029274229617328118, 0.006505384359406249, 0.9003062737127409, 0.02831151804128116, 0.05096073247430608, 0.022649214433024926, 0.13044514572617874, 0.042394672361008086, 0.8250655467180805, 0.0032611286431544683, 0.20646485950722562, 0.12461192703986398, 0.6523800886204644, 0.015881912269786587, 0.15701210956296996, 0.7698658275345625, 0.04051925408076645, 0.03545434732067064, 0.2379254402116318, 0.7137763206348955, 0.03756717477025766, 0.008348261060057257, 0.5475255801249033, 0.3427758709503576, 0.08765642501402274, 0.021587030040766793, 0.33964545625829595, 0.09144300745415661, 0.5617213315041049, 0.006531643389582615, 0.20279554490871307, 0.7626875928088557, 0.02939065868242218, 0.005878131736484437, 0.25847718348779936, 0.6994088494375748, 0.030409080410329338, 0.013032463032998287, 0.08437187811655206, 0.3248317307487254, 0.5273242382284503, 0.06327890858741404, 0.4153461751106282, 0.4004605167369082, 0.1288880176261128, 0.05527662164387513, 0.6286136193454048, 0.08657552841284018, 0.04516984091104705, 0.24090581819225096, 0.8498470960323652, 0.08053713639910674, 0.044475732041297754, 0.025242983050466294, 0.8351444807968562, 0.04330378789317032, 0.061862554133100454, 0.055676298719790414, 0.2353825916079309, 0.29694419249000514, 0.1593359081653686, 0.3114292750504932, 0.6933593282599466, 0.26294439536720327, 0.012521161684152534, 0.029737758999862272, 0.007465435218569078, 0.014930870437138156, 0.14184326915281248, 0.8435941796983059, 0.5910092403952247, 0.2716254589695225, 0.10148643521938203, 0.035818741842134835, 0.46407038842264225, 0.44498854679342176, 0.07556409285171313, 0.01526547330337639, 0.29851564448769047, 0.4093928838688326, 0.025587055241802038, 0.2643995708319544, 0.8085615973131443, 0.05589135465298232, 0.08197398682437407, 0.05589135465298232, 0.8366571701084936, 0.08159705917266902, 0.02528359579998195, 0.05631346337268707, 0.1813894575305576, 0.03886916947083378, 0.05830375420625066, 0.7255578301222304, 0.1608884997755652, 0.11523095254195886, 0.09783760121487073, 0.6261606477751727, 0.12015037680556594, 0.37683527270836586, 0.4897038084954127, 0.014563682037038296, 0.7917078183358356, 0.13080390042070328, 0.06884415811615963, 0.013768831623231923, 0.23430130677796435, 0.7182679404504808, 0.0038410050291469563, 0.04225105532061652, 0.1391430960216096, 0.8053433739432555, 0.050597489462403486, 0.0042164574552002905, 0.1894364254856477, 0.26661422846128197, 0.5402446208294397, 0.007016163906875841, 0.20646167318646233, 0.7408330626102472, 0.03036201076271505, 0.01821720645762903, 0.7725871955641453, 0.13633891686426095, 0.041314823292200285, 0.05370927027986037, 0.004106785263132139, 0.03696106736818926, 0.9609877515729206, 0.16231595173745783, 0.530232109009029, 0.003607021149721285, 0.29938275542686665, 0.8622204983749623, 0.028828040979102083, 0.08648412293730624, 0.020965847984801514, 0.6777151756120332, 0.1787905149095667, 0.10463099948506471, 0.03891538928216442, 0.7226428740462858, 0.24621904018751567, 0.020017808145326478, 0.012010684887195887, 0.22630191262487237, 0.06092743801438871, 0.002901306572113748, 0.7079188035957545, 0.6170114073587645, 0.1979600679233002, 0.11189047317403925, 0.0736970905040547, 0.8464094170172163, 0.06176952352985602, 0.04674450429286402, 0.045075057710976016, 0.39134894372429957, 0.08524432437559, 0.042622162187795, 0.4843427521340341, 0.10829529460423636, 0.18564907646440518, 0.06188302548813506, 0.6497717676254181, 0.3046579630639105, 0.6490805197004198, 0.028752859967879102, 0.017741126363159446, 0.5949144124685446, 0.2650499538165375, 0.1009451437011995, 0.038888702901281776, 0.34261601982307155, 0.5246755784738251, 0.10608194756028157, 0.02723725680601824, 0.5405561224812122, 0.2728575973500074, 0.13356264744233556, 0.052737182681093876, 0.44259174599705287, 0.5219530245896279, 0.03204974712392452, 0.0038154460861814904, 0.30523404465032977, 0.1116709919452426, 0.5806891581152616, 0.5015406372505459, 0.34729553615938047, 0.09591507077346206, 0.05515726716234714, 0.43284336494373954, 0.5174345809352825, 0.037901259113093944, 0.012084459427363286, 0.2289600097723603, 0.7653806040961759, 0.00654171456492458, 0.00654171456492458, 0.9950464149673202, 0.09254582483155296, 0.381751527430156, 0.08097759672760885, 0.45116089605382076, 0.03810603049371388, 0.11431809148114164, 0.8383326708617054, 0.007621206098742775, 0.8126452068326395, 0.11870098526768892, 0.07304676016473165, 0.1564291500661204, 0.111735107190086, 0.6882882602909298, 0.049163447163637845, 0.21588523870460294, 0.07001683417446582, 0.5309609924896991, 0.1867115577985755, 0.18903599225731765, 0.7417868050603604, 0.02632146727633537, 0.040678631245245574, 0.7124041189046735, 0.12418876081598147, 0.09564477367295805, 0.06769856636539062, 0.2594288784443913, 0.38914331766658694, 0.005294466907028394, 0.3467875824103598, 0.23345934258134088, 0.13132088020200425, 0.6274219831873536, 0.0072956044556669025, 0.13556581608240698, 0.8487598919942002, 0.011788331833252782, 0.6614409897720133, 0.22027232961275536, 0.08860813259209989, 0.02995204481986475, 0.5564018682659536, 0.3240091200745513, 0.08323682567432439, 0.03631136690490661, 0.36408163080945244, 0.41773576587610856, 0.1410337264609247, 0.07741525202474672, 0.5300138471852271, 0.4272120905302528, 0.02092969895969538, 0.022160857722030403, 0.7288898024786392, 0.13963199618488725, 0.10566745657234711, 0.02587774446669725, 0.8069157059305168, 0.0857347937551174, 0.07060512426892021, 0.04034578529652584, 0.41236105812420526, 0.402974994585718, 0.13328210224651854, 0.05131048067706347, 0.5286912528132608, 0.3385450465269369, 0.09686693527793859, 0.03587664269553281, 0.8141125729507066, 0.11630179613581523, 0.04652071845432609, 0.015506906151442032, 0.8444212534477051, 0.05567612660094759, 0.08351418990142138, 0.01855870886698253, 0.14191979782745956, 0.7387107425378023, 0.11644701360201809, 0.007277938350126131, 0.43068793344332884, 0.3948292889699027, 0.12934725327914426, 0.045207505353997944, 0.49236608757997985, 0.33142471786714406, 0.11577600508986606, 0.06043253012932569, 0.8129954891155162, 0.0396583165422203, 0.1189749496266609, 0.02776082157955421, 0.7490633620749643, 0.09828136310912652, 0.06375007336808207, 0.08765635088111284, 0.33431287459418846, 0.20169289128409718, 0.33293141643470836, 0.12985706699113106, 0.5679183428618506, 0.29348326786401224, 0.10017938470358109, 0.03880187435702085, 0.4214773024069248, 0.5019411510482469, 0.0406150855046673, 0.036017151296591755, 0.018209843938728317, 0.0036419687877456636, 0.9760476351158378, 0.6157680574970039, 0.27392133487790293, 0.07014517165430902, 0.03995611043599881, 0.590856612590689, 0.19603827285491537, 0.14325873785551507, 0.07060119616802896, 0.06762564808053094, 0.8994211194710615, 0.020287694424159283, 0.0067625648080530945, 0.7916301530194236, 0.08552788085385733, 0.08154983988391047, 0.03978040969946853, 0.09158555961748234, 0.21980534308195762, 0.6838388451438682, 0.0061057039744988224, 0.69475573679485, 0.1535079342251478, 0.11446927853858005, 0.03705363929572533, 0.30578877389673975, 0.6647582041233473, 0.01772688544328926, 0.013295164082466945, 0.22011300784619917, 0.3668550130769986, 0.2423466450023809, 0.17342236981821751, 0.8110743314611194, 0.17135373199882806, 0.005711791066627602, 0.011423582133255204, 0.4594955161182693, 0.41038912508272907, 0.08505928447227504, 0.045598791675858785, 0.2373941056913239, 0.34026488482423095, 0.007913136856377463, 0.4114831165316281, 0.16775155781601075, 0.45809079249756784, 0.00645198299292349, 0.36776303059663895, 0.6106892438712035, 0.23204876543222264, 0.10189110096882296, 0.0552184031056847, 0.3630552178916952, 0.04950752971250389, 0.09901505942500778, 0.47857278722087093, 0.4528549248481747, 0.057923304341045596, 0.11584660868209119, 0.3738686007467489, 0.5309601011220962, 0.32257460162305485, 0.08458452009186182, 0.061516014612263144, 0.06877428104990285, 0.04584952069993523, 0.8803107974387565, 0.004584952069993524, 0.15572468248623023, 0.04449276642463721, 0.7934543345726969, 0.014830922141545737, 0.039743377826396004, 0.023846026695837602, 0.9299950411376664, 0.0079486755652792, 0.214374397787652, 0.014484756607273783, 0.0028969513214547565, 0.7676921001855105, 0.8539956362172783, 0.1362758993963742, 0.00908505995975828, 0.00908505995975828, 0.16878332763353696, 0.01834601387321054, 0.3779278857881371, 0.4329659274077687, 0.31480868480443447, 0.09950849232324079, 0.4685945365767157, 0.11760094547292092, 0.03536497758563768, 0.009644993886992095, 0.9548543948122175, 0.0032149979623306985, 0.30414827624892016, 0.15207413812446008, 0.5407080466647469, 0.2716726233072417, 0.7213376549881935, 0.009368021493353161, 0.1768448880548811, 0.7350115659780997, 0.0055264027517150345, 0.07736963852401049, 0.7870883191274045, 0.1208249612695577, 0.06559069326061705, 0.027617134004470335, 0.09343254147159588, 0.7674815906595376, 0.13347505924513697, 0.006673752962256849, 0.08745227163155732, 0.08045608990103274, 0.8255494442019011, 0.006996181730524586, 0.26401430720685853, 0.09266727339048678, 0.6206958878042038, 0.020981269446902664, 0.44487936790328614, 0.14971901804437512, 0.3695920902581146, 0.035077027084682175, 0.3226878137120545, 0.5686888038717115, 0.093919817609116, 0.014648044948210752, 0.9541067307503234, 0.008120057282981475, 0.024360171848944425, 0.012180085924472213, 0.34446113839728343, 0.08470355862228282, 0.20046508873940266, 0.3698722059839683, 0.44614926518120945, 0.07873222326727225, 0.23619666980181678, 0.23619666980181678, 0.21382098576145808, 0.7231036973023856, 0.03498888857914769, 0.027213580006003758, 0.9912067436339753, 0.3969840451341492, 0.5000682999479891, 0.06470181951081437, 0.03838243530302547, 0.66810255096599, 0.21118184082258307, 0.07871323157932641, 0.04223636816451661, 0.733859145493496, 0.1575638753559565, 0.07122750529789815, 0.03741242702515862, 0.49841356225802735, 0.33382283718571315, 0.11246437830320818, 0.05533961472062625, 0.19415528675420224, 0.06177668214906435, 0.7413201857887722, 0.11380721334475848, 0.07187824000721588, 0.8086302000811786, 0.005796518546892319, 0.005796518546892319, 0.9912046715185866, 0.06418420021249897, 0.01426315560277755, 0.9199735363791519, 0.6367817250350848, 0.26310143130192126, 0.05567073763779783, 0.04346893212814351, 0.4064413453891625, 0.4182091348993164, 0.13035089918939732, 0.04435551430750326, 0.0041712057410897875, 0.0041712057410897875, 0.9885757606382797, 0.3960783852203493, 0.2829131323002495, 0.050924363814044915, 0.27159660700823957, 0.22731089153618506, 0.6965038856044644, 0.06411332838200091, 0.014571210995909299, 0.06977212455718107, 0.516690868342368, 0.4110898149585263, 0.001885733096140029, 0.7864911217658096, 0.04289951573268053, 0.09294895075414114, 0.07507415253219092, 0.6363550319038713, 0.19414221312321497, 0.09707110656160749, 0.07190452337896851, 0.5579482234870051, 0.36092793092037717, 0.05353212431082047, 0.027593878510732202, 0.2766810419081031, 0.7147593582625997, 0.35448868214691914, 0.1566345339718945, 0.1566345339718945, 0.32975691362504106, 0.48871216623539837, 0.38325639670248257, 0.07713336285836127, 0.05122137377313053, 0.3543248174189087, 0.5100719899107367, 0.1207040586811667, 0.014601297421108874, 0.38922405420676537, 0.3982160290564266, 0.1560749920334059, 0.05716326868713221, 0.2630820742383157, 0.6178262286411124, 0.0880908302879428, 0.032141248888843996], \"Term\": [\"action\", \"action\", \"action\", \"action\", \"adult\", \"adult\", \"adult\", \"affair\", \"affair\", \"affair\", \"affair\", \"alien\", \"alien\", \"alien\", \"alien\", \"american\", \"american\", \"american\", \"american\", \"animate\", \"animate\", \"animate\", \"animation\", \"animation\", \"animation\", \"ape\", \"ape\", \"army\", \"army\", \"army\", \"army\", \"art\", \"art\", \"art\", \"art\", \"artist\", \"artist\", \"artist\", \"artist\", \"awful\", \"awful\", \"awful\", \"awful\", \"bad\", \"bad\", \"bad\", \"bad\", \"batman\", \"batman\", \"batman\", \"batman\", \"beauty\", \"beauty\", \"beauty\", \"big\", \"big\", \"big\", \"big\", \"blood\", \"blood\", \"blood\", \"blood\", \"bob\", \"bob\", \"bob\", \"bob\", \"bond\", \"bond\", \"bond\", \"bond\", \"boring\", \"boring\", \"boring\", \"boring\", \"brown\", \"brown\", \"brown\", \"brown\", \"bunch\", \"bunch\", \"bunch\", \"bunch\", \"cameron\", \"cameron\", \"cameron\", \"car\", \"car\", \"car\", \"car\", \"carter\", \"carter\", \"carter\", \"carter\", \"chan\", \"chan\", \"chan\", \"character\", \"character\", \"character\", \"character\", \"child\", \"child\", \"child\", \"child\", \"cinematography\", \"cinematography\", \"cinematography\", \"cinematography\", \"college\", \"college\", \"college\", \"college\", \"color\", \"color\", \"color\", \"color\", \"come\", \"come\", \"come\", \"come\", \"comedy\", \"comedy\", \"comedy\", \"comedy\", \"complex\", \"complex\", \"complex\", \"complex\", \"computer\", \"computer\", \"computer\", \"country\", \"country\", \"country\", \"country\", \"creature\", \"creature\", \"creature\", \"creature\", \"crew\", \"crew\", \"crew\", \"crew\", \"cute\", \"cute\", \"cute\", \"cute\", \"daughter\", \"daughter\", \"daughter\", \"daughter\", \"death\", \"death\", \"death\", \"death\", \"desire\", \"desire\", \"desire\", \"detective\", \"detective\", \"detective\", \"detective\", \"disney\", \"disney\", \"disney\", \"dr\", \"dr\", \"dr\", \"dr\", \"dream\", \"dream\", \"dream\", \"dream\", \"dumb\", \"dumb\", \"dumb\", \"dumb\", \"earth\", \"earth\", \"earth\", \"earth\", \"effect\", \"effect\", \"effect\", \"effect\", \"effective\", \"effective\", \"effective\", \"effective\", \"emotional\", \"emotional\", \"emotional\", \"emotional\", \"end\", \"end\", \"end\", \"end\", \"episode\", \"episode\", \"episode\", \"episode\", \"family\", \"family\", \"family\", \"family\", \"father\", \"father\", \"father\", \"father\", \"fiction\", \"fiction\", \"fiction\", \"fiction\", \"film\", \"film\", \"film\", \"film\", \"flick\", \"flick\", \"flick\", \"flick\", \"funny\", \"funny\", \"funny\", \"funny\", \"gag\", \"gag\", \"gag\", \"gag\", \"genre\", \"genre\", \"genre\", \"genre\", \"girl\", \"girl\", \"girl\", \"girl\", \"godzilla\", \"godzilla\", \"godzilla\", \"godzilla\", \"good\", \"good\", \"good\", \"good\", \"great\", \"great\", \"great\", \"great\", \"guard\", \"guard\", \"guard\", \"guard\", \"guess\", \"guess\", \"guess\", \"guess\", \"guy\", \"guy\", \"guy\", \"guy\", \"harry\", \"harry\", \"harry\", \"harry\", \"horror\", \"horror\", \"horror\", \"horror\", \"human\", \"human\", \"human\", \"human\", \"hunt\", \"hunt\", \"hunt\", \"hunt\", \"husband\", \"husband\", \"husband\", \"husband\", \"image\", \"image\", \"image\", \"image\", \"impact\", \"impact\", \"impact\", \"impact\", \"issue\", \"issue\", \"issue\", \"issue\", \"jack\", \"jack\", \"jack\", \"jack\", \"jackie\", \"jackie\", \"jackie\", \"joe\", \"joe\", \"joe\", \"joe\", \"joke\", \"joke\", \"joke\", \"joke\", \"just\", \"just\", \"just\", \"just\", \"kid\", \"kid\", \"kid\", \"kid\", \"killer\", \"killer\", \"killer\", \"killer\", \"know\", \"know\", \"know\", \"know\", \"laugh\", \"laugh\", \"laugh\", \"laugh\", \"lee\", \"lee\", \"lee\", \"lee\", \"legend\", \"legend\", \"legend\", \"legend\", \"life\", \"life\", \"life\", \"life\", \"like\", \"like\", \"like\", \"like\", \"live\", \"live\", \"live\", \"live\", \"look\", \"look\", \"look\", \"look\", \"love\", \"love\", \"love\", \"love\", \"machine\", \"machine\", \"machine\", \"make\", \"make\", \"make\", \"make\", \"man\", \"man\", \"man\", \"man\", \"marry\", \"marry\", \"marry\", \"marry\", \"mars\", \"master\", \"master\", \"master\", \"master\", \"menace\", \"menace\", \"menace\", \"menace\", \"mike\", \"mike\", \"mike\", \"mission\", \"mission\", \"mission\", \"mission\", \"monster\", \"monster\", \"monster\", \"monster\", \"mother\", \"mother\", \"mother\", \"mother\", \"movie\", \"movie\", \"movie\", \"movie\", \"murder\", \"murder\", \"murder\", \"murder\", \"murphy\", \"murphy\", \"murphy\", \"murphy\", \"musical\", \"musical\", \"musical\", \"nand\", \"nand\", \"nand\", \"nand\", \"nbut\", \"nbut\", \"nbut\", \"nbut\", \"new\", \"new\", \"new\", \"new\", \"nhe\", \"nhe\", \"nhe\", \"nhe\", \"ni\", \"ni\", \"ni\", \"ni\", \"nim\", \"nim\", \"nim\", \"nim\", \"nin\", \"nin\", \"nin\", \"nin\", \"nit\", \"nit\", \"nit\", \"nit\", \"nmaybe\", \"nmaybe\", \"nmaybe\", \"nmaybe\", \"noh\", \"noh\", \"noh\", \"noh\", \"novel\", \"novel\", \"novel\", \"novel\", \"nthe\", \"nthe\", \"nthe\", \"nthe\", \"nthis\", \"nthis\", \"nthis\", \"nthis\", \"nwell\", \"nwell\", \"nwell\", \"nwell\", \"nyou\", \"nyou\", \"nyou\", \"nyou\", \"original\", \"original\", \"original\", \"original\", \"people\", \"people\", \"people\", \"people\", \"performance\", \"performance\", \"performance\", \"performance\", \"planet\", \"planet\", \"planet\", \"play\", \"play\", \"play\", \"play\", \"plot\", \"plot\", \"plot\", \"plot\", \"political\", \"political\", \"political\", \"political\", \"pretty\", \"pretty\", \"pretty\", \"pretty\", \"race\", \"race\", \"race\", \"race\", \"really\", \"really\", \"really\", \"really\", \"relationship\", \"relationship\", \"relationship\", \"relationship\", \"release\", \"release\", \"release\", \"release\", \"robin\", \"robin\", \"robin\", \"robin\", \"role\", \"role\", \"role\", \"role\", \"rush\", \"rush\", \"rush\", \"rush\", \"sam\", \"sam\", \"sam\", \"sam\", \"say\", \"say\", \"say\", \"say\", \"scare\", \"scare\", \"scare\", \"scare\", \"scary\", \"scary\", \"scary\", \"scary\", \"scene\", \"scene\", \"scene\", \"scene\", \"science\", \"science\", \"science\", \"science\", \"scientist\", \"scientist\", \"scientist\", \"scientist\", \"scifi\", \"scifi\", \"scifi\", \"scifi\", \"scream\", \"scream\", \"scream\", \"scream\", \"sean\", \"sean\", \"sean\", \"sean\", \"sequel\", \"sequel\", \"sequel\", \"sequel\", \"series\", \"series\", \"series\", \"series\", \"ship\", \"ship\", \"ship\", \"ship\", \"simon\", \"simon\", \"simon\", \"singer\", \"singer\", \"singer\", \"sister\", \"sister\", \"sister\", \"sister\", \"sit\", \"sit\", \"sit\", \"sit\", \"soldier\", \"soldier\", \"soldier\", \"soldier\", \"space\", \"space\", \"space\", \"space\", \"special\", \"special\", \"special\", \"special\", \"star\", \"star\", \"star\", \"star\", \"story\", \"story\", \"story\", \"story\", \"stupid\", \"stupid\", \"stupid\", \"stupid\", \"summer\", \"summer\", \"summer\", \"summer\", \"suspense\", \"suspense\", \"suspense\", \"suspense\", \"tale\", \"tale\", \"tale\", \"tale\", \"tarzan\", \"tell\", \"tell\", \"tell\", \"tell\", \"thing\", \"thing\", \"thing\", \"thing\", \"think\", \"think\", \"think\", \"think\", \"time\", \"time\", \"time\", \"time\", \"titanic\", \"titanic\", \"titanic\", \"toy\", \"toy\", \"toy\", \"trek\", \"trek\", \"trek\", \"truman\", \"truman\", \"truman\", \"try\", \"try\", \"try\", \"try\", \"use\", \"use\", \"use\", \"use\", \"vampire\", \"vampire\", \"vampire\", \"victim\", \"victim\", \"victim\", \"victim\", \"voice\", \"voice\", \"voice\", \"voice\", \"war\", \"war\", \"war\", \"war\", \"waste\", \"waste\", \"waste\", \"waste\", \"watch\", \"watch\", \"watch\", \"watch\", \"way\", \"way\", \"way\", \"way\", \"wedding\", \"wedding\", \"wood\", \"wood\", \"wood\", \"wood\", \"work\", \"work\", \"work\", \"work\", \"world\", \"world\", \"world\", \"world\", \"year\", \"year\", \"year\", \"year\", \"young\", \"young\", \"young\", \"young\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 4, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el9091553505607203031992176\", ldavis_el9091553505607203031992176_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el9091553505607203031992176\", ldavis_el9091553505607203031992176_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el9091553505607203031992176\", ldavis_el9091553505607203031992176_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "0     -0.000811 -0.018993       1        1  47.823504\n",
       "1     -0.016512 -0.054180       2        1  34.965051\n",
       "3     -0.063002  0.047357       3        1  11.493649\n",
       "2      0.080325  0.025815       4        1   5.717796, topic_info=       Term          Freq         Total Category  logprob  loglift\n",
       "321    film  11017.000000  11017.000000  Default  30.0000  30.0000\n",
       "537   movie   6691.000000   6691.000000  Default  29.0000  29.0000\n",
       "603    nthe   7808.000000   7808.000000  Default  28.0000  28.0000\n",
       "25    alien    602.000000    602.000000  Default  27.0000  27.0000\n",
       "261  effect    818.000000    818.000000  Default  26.0000  26.0000\n",
       "..      ...           ...           ...      ...      ...      ...\n",
       "667    plot    103.110522   1458.898795   Topic4  -5.3078   0.2120\n",
       "563     new    100.929185   1304.652473   Topic4  -5.3292   0.3023\n",
       "580     nit    109.955540   3066.061697   Topic4  -5.2435  -0.4665\n",
       "445    just    105.951695   2723.858143   Topic4  -5.2806  -0.3852\n",
       "609   nthis     94.984006   1572.001036   Topic4  -5.3899   0.0552\n",
       "\n",
       "[267 rows x 6 columns], token_table=      Topic      Freq    Term\n",
       "term                         \n",
       "10        1  0.558743  action\n",
       "10        2  0.159393  action\n",
       "10        3  0.213968  action\n",
       "10        4  0.068435  action\n",
       "17        1  0.161713   adult\n",
       "...     ...       ...     ...\n",
       "996       4  0.057163    year\n",
       "999       1  0.263082   young\n",
       "999       2  0.617826   young\n",
       "999       3  0.088091   young\n",
       "999       4  0.032141   young\n",
       "\n",
       "[717 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 2, 4, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.sklearn.prepare(pipe['lda'] , pipe['vectorize'].fit_transform(processed), pipe['vectorize'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The visualization here can help determine a reasonable number of\n",
    "number of clusters and it can serve as a communication tool.  If the\n",
    "goal was to find topics that are associated with customer profiles\n",
    "then you would likely work with folks in marketing to refine the\n",
    "clustering.  There are a couple of parameters than can be used to\n",
    "modify the clustering and visualization.  The discovery of meaningful\n",
    "topics is a form of feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## QUESTION 6\n",
    "\n",
    "If you were to use the topics from this model to inform clustering or\n",
    "supervised learning you would first need to be able to extract and\n",
    "represent them as a matrix.  Along the same lines if you were to\n",
    "populate a report with tabular descriptions of the data then you will\n",
    "need to be able to extract topic representations.  Here is a starter\n",
    "function\n",
    "\n",
    "```python\n",
    "def get_top_words(model, feature_names, n_top_words):\n",
    "    top_words = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        _top_words = [feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "        top_words[str(topic_idx)] = _top_words\n",
    "    return(top_words)\n",
    "```\n",
    "\n",
    "Use the function to print the top k words for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## QUESTION (EXTRA CREDIT) 7\n",
    "\n",
    "If you used `fit_transform` on your original tokens you should have a `2000 x k` array where `k` is the number of topics you choose.  Create a PCA or tSNE visualization that projects the tf matrix into lower dimensional space then uses colors to indicate which documents belong to a topic (e.g. probability > 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/Users/marcohassan/Desktop/python_venv/TreeSchutz/bin/python3",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "TreeSchutz",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "treeschutz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "name": "topic_modeling-case-study.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
