{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "![ibm cloud logo](../images/ibm-cloud.png)\n",
    "\n",
    "# CASE STUDY - unsupervised learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.svm import SVC\n",
    "import imblearn.pipeline as pl\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE, SVMSMOTE\n",
    "    \n",
    "    \n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Synopsis\n",
    "\n",
    "  > We are now going to predict customer retention.  There are many models and many transforms to consider.  Use your\n",
    "    knowledge of pipelines and functions to ensure that your code makes it easy to compare and iterate.  \n",
    "    \n",
    "  > Marketing has asked you to make a report on customer retention.  They would like you to come up with information     that can be used to improve current marketing strategy efforts.  The current plan is for marketing at AAVAIL to\n",
    "    collect more features on subscribers the and they would like to use your report as a proof-of-concept in order to     get buyin for this effort.\n",
    "  \n",
    "## Outline\n",
    "\n",
    "1. Create a churn prediction baseline model\n",
    "2. Use clustering as part of your prediction pipeline\n",
    "3. \n",
    "4. Run and experiment to see if re-sampling techniques improve your model\n",
    "\n",
    "## Data\n",
    "\n",
    "Here we load the data as we have already done.\n",
    "\n",
    "`aavail-target.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n      <th>age</th>\n      <th>subscriber_type</th>\n      <th>num_streams</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>united_states</td>\n      <td>21</td>\n      <td>aavail_premium</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>singapore</td>\n      <td>30</td>\n      <td>aavail_unlimited</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>united_states</td>\n      <td>21</td>\n      <td>aavail_premium</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>united_states</td>\n      <td>20</td>\n      <td>aavail_basic</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>singapore</td>\n      <td>21</td>\n      <td>aavail_premium</td>\n      <td>23</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
      ],
      "text/plain": [
       "         country  age   subscriber_type  num_streams\n0  united_states   21    aavail_premium           23\n1      singapore   30  aavail_unlimited           12\n2  united_states   21    aavail_premium           22\n3  united_states   20      aavail_basic           19\n4      singapore   21    aavail_premium           23"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(\".\",r\"aavail-target.csv\"))\n",
    "\n",
    "## pull out the target and remove uneeded columns\n",
    "_y = df.pop('is_subscriber')\n",
    "y = np.zeros(_y.size)\n",
    "y[_y==0] = 1 \n",
    "df.drop(columns=['customer_id','customer_name'],inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### QUESTION 1\n",
    "\n",
    "Create a stratified train test split of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "rs = 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.25, stratify=y, random_state=rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### QUESTION 2\n",
    "\n",
    "Create a baseline model.  We are going to test whether clustering\n",
    "followed by a model improves the results.  The we will test whether\n",
    "re-sampling techniques provide improvements.  Use a pipeline or\n",
    "another method, but create a baseline model given the data. Here is\n",
    "the ColumnTransformer we have used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "## preprocessing pipeline\n",
    "numeric_features = ['age', 'num_streams']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['country', 'subscriber_type']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-->svm\n",
      "f1_score 0.609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-->rf\n",
      "f1_score 0.538\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE\n",
    "param_grid_svm = {\n",
    "    'svm__C': [0.01,0.1,0.5,1.0,1.5,5.0,10.0],\n",
    "    'svm__gamma': [0.001,0.01,0.1]\n",
    "}\n",
    "best_params = {}\n",
    "pipe_svm = Pipeline(steps=[('pre', preprocessor),\n",
    "                           ('svm',SVC(kernel='rbf',\n",
    "                                      class_weight='balanced'))])\n",
    "grid = GridSearchCV(pipe_svm,\n",
    "                    param_grid=param_grid_svm,\n",
    "                    cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "print(\"-->\".join(pipe_svm.named_steps.keys()))\n",
    "best_params = grid.best_params_\n",
    "\n",
    "print(\"f1_score\",round(f1_score(y_test, y_pred,average='binary'),3))\n",
    "\n",
    "param_grid_rf = {\n",
    "    'rf__n_estimators': [20,50,100,150],\n",
    "    'rf__max_depth': [4, 5, 6, 7, 8],\n",
    "    'rf__criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "pipe_rf = Pipeline(steps=[('pre', preprocessor),\n",
    "                          ('rf',RandomForestClassifier())])\n",
    "\n",
    "grid = GridSearchCV(pipe_rf,\n",
    "                    param_grid=param_grid_rf,\n",
    "                    cv=5)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "print(\"-->\".join(pipe_rf.named_steps.keys()))\n",
    "best_params = dict(best_params, **grid.best_params_)\n",
    "print(\"f1_score\",round(f1_score(y_test, y_pred,average='binary'),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### QUESTION 3\n",
    "\n",
    "The next part is to create version of the classifier that uses\n",
    "identified clusters. I.e. you would create 4 new features based on 4\n",
    "identified clusters in the data and you would use such clustering as\n",
    "new feature for the classification job as performed above. This is\n",
    "similar to the idea you had in the project when you wanted to classify\n",
    "the input of fire, health etc. and then based on that perform your\n",
    "classificiation task.\n",
    "\n",
    "Here is a class to get you started.  It is a transformer like those\n",
    "that we have been working with.\n",
    "\n",
    "There is an example of how to use it just below.  In this example 4\n",
    "clusters were specified and their one-hot encoded versions were\n",
    "appended to the feature matrix.  Now using pipelines and/or functions\n",
    "compare the performance using cluster profiling as part of your matrix\n",
    "to the baseline.  You may compare multiple models and multiple\n",
    "clustering algorithms here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check how the feature space is increased by the cluster dummy obtained via the clustering algo.\n",
      "-----------------------------------\n",
      "\n",
      "(750, 7)\n",
      "(750, 11)\n",
      "\n",
      "(750, 7)\n",
      "(750, 11)\n"
     ]
    }
   ],
   "source": [
    "class KmeansTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k=4):\n",
    "        self.km = KMeans(n_clusters=k,n_init=20)\n",
    "        \n",
    "    def transform(self, X, *_):\n",
    "        labels = self.km.predict(X)\n",
    "        enc = OneHotEncoder(categories='auto')\n",
    "        oh_labels = enc.fit_transform(labels.reshape(-1,1))\n",
    "        oh_labels = oh_labels.todense()\n",
    "        return(np.hstack((X,oh_labels)))\n",
    "\n",
    "    def fit(self,X,y=None,*_):\n",
    "        self.km.fit(X)\n",
    "        labels = self.km.predict(X)\n",
    "        self.silhouette_score = round(silhouette_score(X,labels,metric='mahalanobis'),3)\n",
    "        return(self)\n",
    "\n",
    "class GmmTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k=4):\n",
    "        self.gmm = BayesianGaussianMixture(n_components=k,covariance_type='full',\n",
    "                                           max_iter=500,n_init=10,warm_start=True)        \n",
    "    def transform(self, X,*_):\n",
    "        probs = self.gmm.predict_proba(X) + np.finfo(float).eps\n",
    "        return(np.hstack((X,probs)))\n",
    "        \n",
    "    def fit(self,X,y=None,*_):\n",
    "        self.gmm.fit(X)\n",
    "        labels = self.gmm.predict(X)\n",
    "        self.silhouette_score = round(silhouette_score(X,labels,metric='mahalanobis'),3)\n",
    "        return(self)\n",
    "    \n",
    "## example for GMM  \n",
    "preprocessor.fit(X_train)\n",
    "X_train_pre = preprocessor.transform(X_train)    \n",
    "gt = GmmTransformer(4)\n",
    "gt.fit(X_train_pre)\n",
    "X_train_gmm = gt.transform(X_train_pre)\n",
    "\n",
    "print(\"Check how the feature space is increased by the cluster dummy obtained via the clustering algo.\\n{}\\n\".format(\"-\"*35))\n",
    "print(X_train_pre.shape); print(X_train_gmm.shape)\n",
    "\n",
    "## example for kmeans\n",
    "preprocessor.fit(X_train)\n",
    "X_train_pre = preprocessor.transform(X_train)    \n",
    "kt = KmeansTransformer(4)\n",
    "kt.fit(X_train_pre)\n",
    "X_train_kmeans = kt.transform(X_train_pre)\n",
    "\n",
    "\n",
    "print(\"\\n{}\\n{}\".format(X_train_pre.shape, X_train_kmeans.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>svm-kmeans</th>\n      <th>svm-gmm</th>\n      <th>rf-kmeans</th>\n      <th>rf-gmm</th>\n    </tr>\n    <tr>\n      <th>n_clusters</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>0.538</td>\n      <td>0.538</td>\n      <td>0.538</td>\n      <td>0.534</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.538</td>\n      <td>0.538</td>\n      <td>0.533</td>\n      <td>0.542</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.538</td>\n      <td>0.538</td>\n      <td>0.525</td>\n      <td>0.538</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.538</td>\n      <td>0.538</td>\n      <td>0.524</td>\n      <td>0.538</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.538</td>\n      <td>0.538</td>\n      <td>0.516</td>\n      <td>0.520</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
      ],
      "text/plain": [
       "            svm-kmeans  svm-gmm  rf-kmeans  rf-gmm\nn_clusters                                        \n3                0.538    0.538      0.538   0.534\n4                0.538    0.538      0.533   0.542\n5                0.538    0.538      0.525   0.538\n6                0.538    0.538      0.524   0.538\n7                0.538    0.538      0.516   0.520"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_clustering_pipeline(smodel,umodel):\n",
    "    fscores,sscores = [],[]\n",
    "    for n_clusters in np.arange(3,8):\n",
    "        \n",
    "        if smodel == 'rf':\n",
    "            clf = RandomForestClassifier(n_estimators=best_params['rf__n_estimators'],\n",
    "                                         max_depth=best_params['rf__max_depth'],\n",
    "                                         criterion=best_params['rf__criterion'])\n",
    "        elif smodel == 'svm':\n",
    "            clf = SVC(C=best_params[\"svm__C\"],\n",
    "                      gamma=best_params[\"svm__gamma\"])\n",
    "        else:\n",
    "            raise Exception(\"invalid supervised learning model\")\n",
    "        \n",
    "        if umodel == 'gmm':\n",
    "            cluster = GmmTransformer(n_clusters)\n",
    "            \n",
    "        elif umodel == 'kmeans':\n",
    "            cluster = KmeansTransformer(n_clusters)\n",
    "            \n",
    "        else:\n",
    "            raise Exception(\"invalid unsupervised learning model\")\n",
    "        \n",
    "        pipe = Pipeline(steps=[('pre', preprocessor),\n",
    "                               ('clustering', cluster),\n",
    "                               ('classifier', clf)])  \n",
    "        \n",
    "        pipe.fit(X_train, y_train)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        score = round(f1_score(y_test, y_pred, average='binary'),3)\n",
    "        fscores.append(score)\n",
    "        sscores.append(pipe['clustering'].silhouette_score)\n",
    "        \n",
    "    return(fscores)\n",
    "\n",
    "## run the different iteration of the model\n",
    "cp_results = {}\n",
    "cp_results['svm-kmeans'] = run_clustering_pipeline('svm','kmeans')\n",
    "cp_results['svm-gmm'] = run_clustering_pipeline('svm','gmm')\n",
    "cp_results['rf-kmeans'] = run_clustering_pipeline('rf','kmeans')\n",
    "cp_results['rf-gmm'] = run_clustering_pipeline('rf','gmm')\n",
    "\n",
    "## display table of results\n",
    "df_cp = pd.DataFrame(cp_results)\n",
    "df_cp[\"n_clusters\"] = [str(i) for i in np.arange(3,8)]\n",
    "df_cp.set_index(\"n_clusters\",inplace=True)\n",
    "df_cp.head(n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  subscriber       0.80      0.92      0.86       178\n",
      "       churn       0.68      0.44      0.54        72\n",
      "\n",
      "    accuracy                           0.78       250\n",
      "   macro avg       0.74      0.68      0.70       250\n",
      "weighted avg       0.77      0.78      0.76       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## include it in a post about accuracy metrics.\n",
    "print(classification_report(y_test, y_pred, target_names = ['subscriber', 'churn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(0.0, 711), (1.0, 289)])\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "print (collections.Counter(y).items()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### SOLUTION NOTE\n",
    "\n",
    "`svm-kmeans` performs at baseline while `svm-gmm` performs below.  The\n",
    "random forests model potentially sees a small improvement with the\n",
    "addition of clusters.  This is a fairly small dataset with a small\n",
    "number of features.  The utility of adding clustering to the pipeline\n",
    "is generally more apparent in higher dimensional data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## QUESTION 4\n",
    "\n",
    "Run an experiment to see if you can you improve on your workflow with\n",
    "the addition of re-sampling techniques?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "\n",
    "def run_clustering_pipeline(smodel,umodel):\n",
    "    fscores,sscores = [],[]\n",
    "    for n_clusters in np.arange(3,8):\n",
    "        \n",
    "        if smodel == 'rf':\n",
    "            clf = RandomForestClassifier(n_estimators=best_params['rf__n_estimators'],\n",
    "                                         max_depth=best_params['rf__max_depth'],\n",
    "                                         criterion=best_params['rf__criterion'])\n",
    "        elif smodel == 'svm':\n",
    "            clf = SVC(C=best_params[\"svm__C\"],gamma=best_params[\"svm__gamma\"])\n",
    "        else:\n",
    "            raise Exception(\"invalid supervised learning model\")\n",
    "        \n",
    "        if umodel == 'gmm':\n",
    "            cluster = GmmTransformer(n_clusters)    \n",
    "        elif umodel == 'kmeans':\n",
    "            cluster = KmeansTransformer(n_clusters)\n",
    "        else:\n",
    "            raise Exception(\"invalid unsupervised learning model\")\n",
    "        \n",
    "        pipe = pl.Pipeline(steps=[('pre', preprocessor),\n",
    "                                  ('clustering', cluster),\n",
    "                                  ('smote', SMOTE(random_state=42)),\n",
    "                                  ('classifier', clf)])  \n",
    "           \n",
    "        pipe.fit(X_train,y_train) \n",
    "        y_pred = pipe.predict(X_test)    \n",
    "        score = round(f1_score(y_test, y_pred,average='binary'),3)\n",
    "        fscores.append(score)\n",
    "        sscores.append(pipe['clustering'].silhouette_score)\n",
    "        \n",
    "    return(fscores)\n",
    "\n",
    "## run the different iteration of the model\n",
    "cp_results = {}\n",
    "cp_results['svm-kmeans'] = run_clustering_pipeline('svm','kmeans')\n",
    "cp_results['svm-gmm'] = run_clustering_pipeline('svm','gmm')\n",
    "cp_results['rf-kmeans'] = run_clustering_pipeline('rf','kmeans')\n",
    "cp_results['rf-gmm'] = run_clustering_pipeline('rf','gmm')\n",
    "\n",
    "## display table of results\n",
    "df_cp = pd.DataFrame(cp_results)\n",
    "df_cp[\"n_clusters\"] = [str(i) for i in np.arange(3,8)]\n",
    "df_cp.set_index(\"n_clusters\",inplace=True)\n",
    "df_cp.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### SOLUTION NOTE\n",
    "\n",
    "The inclusion of customer profiles does not significantly improve the overall model performance pipeline for either model.  There may be some minor improvement depending on the random seed, but since it does not degrade model performance either it can be useful in the context of marketing.  The clusters are customer profiles that are tied to predictive performance.  The re-sampling does help the random forest classifiers obtain similar performance results to SVM in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/Users/marcohassan/Desktop/python_venv/TreeSchutz/bin/python3",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "TreeSchutz",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "treeschutz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "name": "clustering-case-study-solution.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
