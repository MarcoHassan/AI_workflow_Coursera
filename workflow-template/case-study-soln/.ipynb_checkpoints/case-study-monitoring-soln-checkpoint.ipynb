{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# CASE STUDY - performance monitoring (solution)\n",
    "\n",
    "You will be building your own workflow template in this tutorial.  You\n",
    "already have a Dockerfile and a basic Flask application to build an\n",
    "API.  Lets combine what you have learned about logging to build a\n",
    "``workflow-template`` that can be used to deploy models in a way that\n",
    "facilitates performance monitoring.\n",
    "\n",
    "There are three main parts to this case study.\n",
    "\n",
    "1. Write unit tests for a logger and a logging API endpoint\n",
    "2. Add logging to your Docker container\n",
    "3. Add an API endpoint for logging\n",
    "4. Make sure all tests pass\n",
    "5. Create model performance investigative tooling\n",
    "6. Swap out the iris data for the AAVAIL churn data\n",
    "\n",
    "You may want to eventually rename the directory because in this\n",
    "case-study you will swap out the iris data for `aavail-target.csv`.\n",
    "It reality you will eventually want a library of workflow templates to\n",
    "work from and the naming convention you decide on can help with\n",
    "organization.  This notebook should reside in that source directory\n",
    "regardless of the name.  We suggest that you go through all of the\n",
    "tasks **first** using the iris data **then** copy the template to a\n",
    "new folder and make it work for the AAVAIL churn data.  Eventually you\n",
    "will want a suite of workflow templates that you will be able to\n",
    "select from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import requests\n",
    "from collections import Counter\n",
    "from datetime import date\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Getting started\n",
    "\n",
    "The ``workflow-template.zip`` is a workflow template.  Unpack the\n",
    "directory in a location where you would like the source code to exist.\n",
    "Leaving out the ``static`` directory that contains CSS and JavaScript\n",
    "to render a landing page, the important pieces are shown in the\n",
    "following tree.\n",
    "\n",
    "```\n",
    "├── app.py\n",
    "├── Dockerfile\n",
    "├── model.py\n",
    "├── README.rst\n",
    "├── requirements.txt\n",
    "├── run-tests.py\n",
    "├── templates\n",
    "│   ├── base.html\n",
    "│   ├── dashboard.html\n",
    "│   ├── index.html\n",
    "│   └── running.html\n",
    "└── unittests\n",
    "    ├── ApiTests.py\n",
    "    ├── __init__.py\n",
    "    ├── ModelTests.py\n",
    "```\n",
    "\n",
    "If you plan on modifying the HTML website you will need to modify the\n",
    "files in ``templates``.  The rest of the files you should be familiar\n",
    "with at this point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## TASK 1: Write units test for a logger and a logging API endpoint\n",
    "\n",
    "1. Using `model.py` and `./unittests/ModelTests.py` as an example create `logger.py` and \n",
    "  `./unittests/LoggerTests.py`.\n",
    "2. Modify the files so that there are at a minimum the following tests:\n",
    "\n",
    "    * ensure predict log is automatically created\n",
    "    * ensure train log is automaticall created\n",
    "    * ensure that the train function in model archives last used training data\n",
    "    * ensure that 'n' predictions result in 'n' predict log entries\n",
    "    * ensure that predict gracefully handles NaNs\n",
    "    \n",
    "> IMPORTANT: when writing to a log file from a unit test you will want to ensure that you do not modify or delete existing 'production' logs.  You can test your function with the following code (although it is likely easier to work directly in a terminal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 4 tests in 0.008s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "!python ./unittests/LoggerTests.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## TASK 2: Add an API endpoint for logging\n",
    "\n",
    "In addition to the `predict` and `train` endpoints, create a third\n",
    "endpoint that returns logs.  Remember that there are `train` and\n",
    "`predict` log files and that they are set up to create new files each\n",
    "month.  You will need to ensure that your endpoint can accommodate\n",
    "this and the best way to ensure this is to **first write the unit\n",
    "tests** then write the code.\n",
    "\n",
    "Flask has several functions to help with the sending of files. One example is [send_from_directory](https://flask.palletsprojects.com/en/1.1.x/api/#flask.send_from_directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/marcohassan/Desktop/Learning/AI_workflow_Coursera/workflow-template/case-study-soln\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..{'y_pred': [1], 'y_proba': [[0.004100209127047534, 0.573445936067756, 0.4224538548051963]]}\r\n",
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 4 tests in 0.085s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "!python ./unittests/ApiTests.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## TASK 3: Make sure all tests pass\n",
    "\n",
    "You have been working on specific suites of unit tests.  It is a best\n",
    "practice to double-check that all tests pass after making major\n",
    "changes like the ones you have just completed.\n",
    "\n",
    "> make sure you modify the `./unittests/__init__.py` so that the\n",
    "  LoggerTest suite is also included when running all tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssss..../Users/marcohassan/Desktop/python_venv/coursera_capstone/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator SimpleImputer from version 0.21.3 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\r\n",
      "  UserWarning)\r\n",
      "/Users/marcohassan/Desktop/python_venv/coursera_capstone/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.preprocessing.data module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.\r\n",
      "  warnings.warn(message, FutureWarning)\r\n",
      "/Users/marcohassan/Desktop/python_venv/coursera_capstone/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator StandardScaler from version 0.21.3 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\r\n",
      "  UserWarning)\r\n",
      "/Users/marcohassan/Desktop/python_venv/coursera_capstone/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.3 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\r\n",
      "  UserWarning)\r\n",
      "/Users/marcohassan/Desktop/python_venv/coursera_capstone/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator OneHotEncoder from version 0.21.3 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\r\n",
      "  UserWarning)\r\n",
      "/Users/marcohassan/Desktop/python_venv/coursera_capstone/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator ColumnTransformer from version 0.21.3 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\r\n",
      "  UserWarning)\r\n",
      "/Users/marcohassan/Desktop/python_venv/coursera_capstone/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\r\n",
      "  warnings.warn(message, FutureWarning)\r\n",
      "/Users/marcohassan/Desktop/python_venv/coursera_capstone/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.tree.tree module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.tree. Anything that cannot be imported from sklearn.tree is now part of the private API.\r\n",
      "  warnings.warn(message, FutureWarning)\r\n",
      "/Users/marcohassan/Desktop/python_venv/coursera_capstone/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.21.3 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\r\n",
      "  UserWarning)\r\n",
      "/Users/marcohassan/Desktop/python_venv/coursera_capstone/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.21.3 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\r\n",
      "  UserWarning)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1\r\n",
      "0  6.1  2.8\r\n",
      "E\r\n",
      "======================================================================\r\n",
      "ERROR: test_03_predict (ModelTests.ModelTest)\r\n",
      "test the predict function input\r\n",
      "----------------------------------------------------------------------\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/marcohassan/Desktop/Learning/AI_workflow_Coursera/workflow-template/case-study-soln/unittests/ModelTests.py\", line 58, in test_03_predict\r\n",
      "    result = model_predict(query_data,model,test=True)\r\n",
      "  File \"/Users/marcohassan/Desktop/Learning/AI_workflow_Coursera/workflow-template/case-study-soln/model.py\", line 175, in model_predict\r\n",
      "    y_pred = model.predict(query)\r\n",
      "  File \"/Users/marcohassan/Desktop/python_venv/coursera_capstone/lib/python3.7/site-packages/sklearn/utils/metaestimators.py\", line 119, in <lambda>\r\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)\r\n",
      "  File \"/Users/marcohassan/Desktop/python_venv/coursera_capstone/lib/python3.7/site-packages/sklearn/pipeline.py\", line 407, in predict\r\n",
      "    Xt = transform.transform(Xt)\r\n",
      "  File \"/Users/marcohassan/Desktop/python_venv/coursera_capstone/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\", line 585, in transform\r\n",
      "    .format(self._n_features, X.shape[1]))\r\n",
      "ValueError: Number of features of the input must be equal to or greater than that of the fitted transformer. Transformer n_features is 4 and input n_features is 2.\r\n",
      "\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 9 tests in 0.043s\r\n",
      "\r\n",
      "FAILED (errors=1, skipped=4)\r\n"
     ]
    }
   ],
   "source": [
    "!python ./run-tests.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## TASK 4: Create model performance investigative tooling\n",
    "\n",
    "There are a lot of convenience functions you could create here.\n",
    "Create them directly in this notebook or create them as scripts that\n",
    "you may call from this notebook.\n",
    "\n",
    "Essentially you will need to create a tools that compare the most\n",
    "recently used training data to the most recent predictions.  In\n",
    "reality your tooling should also allow you to compare predictions from\n",
    "say one model to another.  The predictions come from log files.\n",
    "\n",
    "For this task let's focus on the comparison of predictions to\n",
    "established data.\n",
    "\n",
    "1. Use bootstrap samples from the original data to ping the `predict`\n",
    "endpoint.  Also, add a couple of outliers like you did in a few course\n",
    "back with outlier detection.\n",
    "\n",
    "2. Pull the predictions from the log file and summarize the investigation visually "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "\n",
    "from monitoring import get_latest_train_data, get_monitoring_tools\n",
    "\n",
    "## load latest data\n",
    "data = get_latest_train_data()\n",
    "y = data['y']\n",
    "X = data['X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63, 4)\n"
     ]
    }
   ],
   "source": [
    "## generate some data\n",
    "bs_samples = 60\n",
    "subset_indices = np.random.choice(np.arange(X.shape[0]),\n",
    "                                  bs_samples,replace=True).astype(int)\n",
    "mask = np.in1d(np.arange(X.shape[0]),subset_indices)\n",
    "X_bs=X[mask]\n",
    "X_outliers = X[:5].copy()\n",
    "X_outliers['age'] = [88,90,76,80,68]\n",
    "X_outliers['num_streams'] = [111,100,80,90,150]\n",
    "X_query = pd.concat([X_bs,X_outliers])\n",
    "\n",
    "print(X_query.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/predict-2020-7.log\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/Users/marcohassan/Desktop/python_venv/coursera_capstone/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3343\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-22-7d6e01cefbc0>\"\u001b[0m, line \u001b[1;32m13\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    response = literal_eval(r.text)\n",
      "  File \u001b[1;32m\"/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ast.py\"\u001b[0m, line \u001b[1;32m46\u001b[0m, in \u001b[1;35mliteral_eval\u001b[0m\n    node_or_string = parse(node_or_string, mode='eval')\n",
      "\u001b[0;36m  File \u001b[0;32m\"/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ast.py\"\u001b[0;36m, line \u001b[0;32m35\u001b[0;36m, in \u001b[0;35mparse\u001b[0;36m\u001b[0m\n\u001b[0;31m    return compile(source, filename, mode, PyCF_ONLY_AST)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"<unknown>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "## delete the log file so we are starting fresh\n",
    "today = date.today() \n",
    "logfile = os.path.join(\"logs\",\"predict-{}-{}.log\".format(today.year, today.month)) \n",
    "print(logfile)\n",
    "if os.path.exists(logfile):\n",
    "    os.remove(logfile)\n",
    "\n",
    "## ping the API\n",
    "request_json = {'query':X_query.to_dict(),'type':'dict'}\n",
    "port = 5000\n",
    "r = requests.post('http://0.0.0.0:{}/predict'.format(port),json=request_json)\n",
    "\n",
    "## response = literal_eval(r.text)\n",
    "\n",
    "##\n",
    "## print(list(sorted(Counter(response['y_pred']).items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pm_tools = get_monitoring_tools(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>query</th>\n",
       "      <th>model_version</th>\n",
       "      <th>runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.576179e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['singapore', 48, 'aavail_basic', 18]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>000:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.576179e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['united_states', 22, 'aavail_basic', 5]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>000:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.576179e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['singapore', 41, 'aavail_basic', 19]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>000:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.576179e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['singapore', 24, 'aavail_premium', 7]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>000:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.576179e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['united_states', 20, 'aavail_premium', 20]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>000:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp  y_pred                                        query  \\\n",
       "0  1.576179e+09     0.0        ['singapore', 48, 'aavail_basic', 18]   \n",
       "1  1.576179e+09     0.0     ['united_states', 22, 'aavail_basic', 5]   \n",
       "2  1.576179e+09     0.0        ['singapore', 41, 'aavail_basic', 19]   \n",
       "3  1.576179e+09     1.0       ['singapore', 24, 'aavail_premium', 7]   \n",
       "4  1.576179e+09     0.0  ['united_states', 20, 'aavail_premium', 20]   \n",
       "\n",
       "   model_version    runtime  \n",
       "0            0.1  000:00:00  \n",
       "1            0.1  000:00:00  \n",
       "2            0.1  000:00:00  \n",
       "3            0.1  000:00:00  \n",
       "4            0.1  000:00:00  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read in the logged data\n",
    "df = pd.read_csv(logfile)\n",
    "df.drop(columns=[\"unique_id\",\"y_proba\"], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>subscriber_type</th>\n",
       "      <th>num_streams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>singapore</td>\n",
       "      <td>48</td>\n",
       "      <td>aavail_basic</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>united_states</td>\n",
       "      <td>22</td>\n",
       "      <td>aavail_basic</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>singapore</td>\n",
       "      <td>41</td>\n",
       "      <td>aavail_basic</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>singapore</td>\n",
       "      <td>24</td>\n",
       "      <td>aavail_premium</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>united_states</td>\n",
       "      <td>20</td>\n",
       "      <td>aavail_premium</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         country  age subscriber_type  num_streams\n",
       "0      singapore   48    aavail_basic           18\n",
       "1  united_states   22    aavail_basic            5\n",
       "2      singapore   41    aavail_basic           19\n",
       "3      singapore   24  aavail_premium            7\n",
       "4  united_states   20  aavail_premium           20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## reconstruct a data frame from the logged queries\n",
    "queries = [literal_eval(q) for q in df['query'].values]\n",
    "queries = pd.DataFrame(queries)\n",
    "queries.columns = ['country', 'age', 'subscriber_type', 'num_streams']\n",
    "print(queries.shape)\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import wasserstein_distance\n",
    "X_target = pm_tools['preprocessor'].transform(queries)\n",
    "\n",
    "outlier_test = pm_tools['clf_X'].predict(X_target)\n",
    "outliers_X = 100 * (1.0 - (outlier_test[outlier_test==1].size / outlier_test.size))\n",
    "wasserstein_X = wasserstein_distance(pm_tools['X_source'].flatten(),X_target.flatten()) \n",
    "wasserstein_y = wasserstein_distance(pm_tools['y_source'],df['y_pred'].values)\n",
    "\n",
    "if outliers_X >= pm_tools['outlier_X']:\n",
    "    print(\"OUTLIER TEST FAILED: {} >= {}\".format(round(outliers_X,2),\n",
    "                                                 pm_tools['outlier_X']))\n",
    "else:\n",
    "    print(\"OUTLIER TEST PASSED: {} < {}\".format(round(outliers_X,2),\n",
    "                                                pm_tools['outlier_X']))\n",
    "    \n",
    "if wasserstein_X >= pm_tools['wasserstein_X']:\n",
    "    print(\"DISTRIBUTION X TEST FAILED: {} >= {}\".format(round(wasserstein_X,2),\n",
    "                                                        pm_tools['wasserstein_X']))\n",
    "else:\n",
    "    print(\"DISTRIBUTION X TEST PASSED: {} < {}\".format(round(wasserstein_X),\n",
    "                                                       pm_tools['wasserstein_X']))\n",
    "    \n",
    "if wasserstein_y >= pm_tools['wasserstein_y']:\n",
    "    print(\"DISTRIBUTION y TEST FAILED: {} >= {}\".format(round(wasserstein_y,2),\n",
    "                                                        pm_tools['wasserstein_y']))\n",
    "else:\n",
    "    print(\"DISTRIBUTION y TEST PASSED: {} < {}\".format(round(wasserstein_y),\n",
    "                                                       pm_tools['wasserstein_y']))\n",
    "\n",
    "fig = plt.figure(figsize=(10,6),dpi=400)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "x_range = np.arange(outlier_test.size)\n",
    "labels = ['outlier','normal']\n",
    "markerline, stemlines, baseline = ax.stem(x_range, outlier_test, '-.',\n",
    "                                          use_line_collection=True)\n",
    "plt.setp(baseline, 'color', 'r', 'linewidth', 2)\n",
    "ax.set_title(\"outlier visualization\")\n",
    "ax.set_ylabel(\"outlier=-1, normal=1\")\n",
    "ax.set_xlabel(\"queries (in time order)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### SOLUTION NOTE\n",
    "\n",
    "The tests we choose to run are reasonable given the size of the data.\n",
    "We are saving each query and with the reconstructed queries we can\n",
    "test for both outliers and distributional changes in the data.  All of\n",
    "this code would be better organized under `monitoring.py` in a\n",
    "production environment, but we walked through the process here with\n",
    "the hope that it provides some insight.  Be cautioned that the\n",
    "bootstrap and disk read/write portions of this code will take much\n",
    "longer with large data sets and some optimization will be required.\n",
    "For example, you could pre-train and serialize the outlier model(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## TASK 5: Swap out the iris data for the AAVAIL churn data\n",
    "\n",
    "We suggest that you copy the iris example folder to a another directory, then re-create the template to work with the AAVAIL data.  The exercise of changing the dataset is very much aligned with real-world practices since you will often be modifying workflow-templates to meet the needs of a particular business opportunity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!python run-tests.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "## this solution uses the AAVAIL data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/Users/marcohassan/Desktop/python_venv/coursera_capstone/bin/python3.7",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "coursera_capstone",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "coursera_capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "name": "case-study-monitoring-soln.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
